{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlstruct.text import huggingface_tokenize, regex_sentencize, partition_spans, encode_as_tag, split_into_spans, apply_substitutions, apply_deltas\n",
    "from nlstruct.dataloaders import load_from_brat, load_genia_ner\n",
    "from nlstruct.collections import Dataset, Batcher\n",
    "from nlstruct.utils import merge_with_spans, normalize_vocabularies, factorize_rows, df_to_csr, factorize, torch_global as tg\n",
    "from nlstruct.modules.crf import BIODecoder, BIOULDecoder\n",
    "from nlstruct.environment import root, cached\n",
    "from nlstruct.train import seed_all\n",
    "from itertools import chain, repeat\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def select_closest_non_overlapping_gold_mentions(\n",
    "    gold_ids,\n",
    "    gold_sentence_ids,\n",
    "    gold_begins,\n",
    "    gold_ends,\n",
    "    \n",
    "    pred_sentence_ids,\n",
    "    pred_begins,\n",
    "    pred_ends,\n",
    "    \n",
    "    zone_mention_id,\n",
    "    zone_mask,\n",
    "    gold_conflicts,\n",
    "    gold_conflicts_mask,\n",
    "):\n",
    "    \"\"\"\n",
    "    Select non overlapping gold mentions (in gold_ids) that are the closest to those found by the model\n",
    "    Gold mentions are described by gold_* tensors, predicted mentions are described by pred_* tensors\n",
    "    We select at most one gold mention per zone (zone_mention_id + zone_mask) and each time a gold mention\n",
    "    is selected, its overlaps are removed according to the gold_conflicts + gold_conflicts_mask tensors\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Selected gold ids, included in \"gold_ids\"\n",
    "    \"\"\"\n",
    "\n",
    "    device = gold_begins.device\n",
    "    \n",
    "    if len(gold_ids) == 0:\n",
    "        return torch.as_tensor([], dtype=torch.long, device=device)\n",
    "\n",
    "    [rel], [remaining_mask], _ = factorize([zone_mention_id], [zone_mask], reference_values=gold_ids)\n",
    "    remaining_mentions = zone_mention_id[remaining_mask.any(1)]\n",
    "    rel = rel[remaining_mask.any(1)]\n",
    "    remaining_mask = remaining_mask[remaining_mask.any(1)]\n",
    "        \n",
    "    keep_mask = torch.zeros(gold_ids.max()+1, device=device, dtype=torch.bool)\n",
    "    zone_scores = torch.full(remaining_mask.shape, fill_value=-1, device=device, dtype=torch.float)\n",
    "    \n",
    "    if len(pred_begins):\n",
    "        PRED, GOLD = 0, 1\n",
    "        SENTENCE_ID, BEGIN, END = 0, 1, 2\n",
    "        p = torch.stack([pred_sentence_ids, pred_begins, pred_ends], dim=0).unsqueeze(GOLD+1)\n",
    "        g = torch.stack([gold_sentence_ids, gold_begins, gold_ends], dim=0).unsqueeze(PRED+1)\n",
    "\n",
    "        overlap = (torch.min(p[END], g[END]) - torch.max(p[BEGIN], g[BEGIN])).float().clamp(0)\n",
    "        overlap = overlap * 2 / (p[END] - p[BEGIN] + g[END] - g[BEGIN])\n",
    "        score = (p[SENTENCE_ID] == g[SENTENCE_ID]) * overlap\n",
    "        \n",
    "        zone_scores = score.max(0).values[rel]\n",
    "        zone_scores[~remaining_mask] = -1\n",
    "    else:\n",
    "        zone_scores[remaining_mask] = 0\n",
    "    while len(remaining_mask):\n",
    "        best_indexer = torch.arange(zone_scores.shape[0], device=device), zone_scores.argmax(1)\n",
    "        best_mentions = remaining_mentions[best_indexer]\n",
    "        conflicts = gold_conflicts[best_mentions][gold_conflicts_mask[best_mentions]]    \n",
    "        keep_mask[best_mentions] = True\n",
    "        remaining_mask[best_indexer] = False\n",
    "        remaining_mask &= ~(remaining_mentions.unsqueeze(-1) == conflicts).any(-1)\n",
    "        zone_scores[~remaining_mask] = -1\n",
    "        zone_scores = zone_scores[remaining_mask.any(1)]\n",
    "        remaining_mentions = remaining_mentions[remaining_mask.any(1)]\n",
    "        remaining_mask = remaining_mask[remaining_mask.any(1)]\n",
    "    return keep_mask.nonzero()[:, 0]\n",
    "\n",
    "def split_zone_mentions(batch, random_perm=True, observed_zone_sizes=None):\n",
    "    \"\"\"\n",
    "    In a batch, splits mentions between \n",
    "    - those that we will consider as being observed\n",
    "    - and those that we will ask the model to recover\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    random_perm: bool\n",
    "        Shuffle the mentions before splitting them\n",
    "    observed_zone_sizes: int\n",
    "        If not None, selects exactly this number of mentions per zone (=overlapping group of mentions)\n",
    "        Otherwise, any random number from 0 to the maximum of mentions can be observed in each group\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor)\n",
    "        - observed_mentions: flat observed mentions (@mention_id)\n",
    "        - target_mentions: flat target mentions (@mention_id)\n",
    "        - zone_target_mentions: mentions to recover, grouped by zone (n_zones * n_mentions_per_zone)\n",
    "        - target_mask: mask of zone_target_mentions, since every zone can have a different number of picked target mentions\n",
    "    \"\"\"\n",
    "    zone_mention_id = batch[\"zone\", \"@mention_id\"]\n",
    "    zone_mention_mask = batch[\"zone\", \"mention_mask\"]\n",
    "    n_sentences = len(batch[\"sentence\"])\n",
    "    device = zone_mention_id.device\n",
    "    if random_perm:\n",
    "        perm = torch.rand(zone_mention_id.shape, device=device)\n",
    "    else:\n",
    "        perm = torch.zeros(zone_mention_id.shape, device=device, dtype=torch.float)\n",
    "    perm[~zone_mention_mask] = 2\n",
    "    perm = perm.argsort(1)\n",
    "\n",
    "    if observed_zone_sizes is None:\n",
    "        observed_zone_size = ((zone_mention_mask.sum(-1) + 1) * torch.rand(zone_mention_mask.shape[0], dtype=torch.float, device=device)).long()\n",
    "    else:\n",
    "        observed_zone_size = torch.full((zone_mention_mask.shape[0],), fill_value=observed_zone_sizes, device=device, dtype=torch.long)\n",
    "\n",
    "    # Select mentions that will become features\n",
    "    zone_observed_mentions = zone_mention_id[torch.arange(perm.shape[0], device=device).unsqueeze(1), perm]\n",
    "    observed_mask = (torch.arange(zone_mention_mask.shape[1], device=device).unsqueeze(0) < observed_zone_size.unsqueeze(1)) & zone_mention_mask\n",
    "    observed_mentions = zone_observed_mentions[observed_mask]\n",
    "\n",
    "    # Select mentions that will be hidden from the model (ie to recover)\n",
    "    zone_target_mentions = zone_mention_id[torch.arange(perm.shape[0], device=device).unsqueeze(1), perm]\n",
    "    target_mask = (torch.arange(zone_mention_mask.shape[1], device=device).unsqueeze(0) >= observed_zone_size.unsqueeze(1)) & zone_mention_mask\n",
    "    zone_target_mentions = zone_target_mentions[target_mask.any(1)]\n",
    "    target_mask = target_mask[target_mask.any(1)]\n",
    "    target_mentions = zone_target_mentions[target_mask]\n",
    "    return target_mentions, observed_mentions, zone_target_mentions, target_mask\n",
    "\n",
    "def compute_scores(pred_batcher, gold_batcher, queries={}, prefix='val_', verbose=0):\n",
    "    pred=pd.DataFrame(dict(pred_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "    gold=pd.DataFrame(dict(gold_batcher[\"mention\", [\"@zone_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "    gold[\"sentence_id\"] = gold_batcher[\"zone\", \"sentence_id\"][gold[\"@zone_id\"]]\n",
    "\n",
    "    # Merge on spans and ner_label\n",
    "    merged = merge_pred_and_gold(\n",
    "        pred, gold, span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"])\n",
    "    \n",
    "    merged[\"ner_label\"] = np.asarray(vocs[\"ner_label\"])[merged[\"ner_label\"]].astype(str)\n",
    "    metrics = {\n",
    "        **compute_metrics(merged, prefix=prefix),\n",
    "        #**compute_metrics(merged.query(\"ner_label == {}\".format(list(vocs[\"ner_label\"]).index(c[\"sosy\"]))), prefix=prefix+\"sosy_\"),\n",
    "        #**compute_metrics(merged.query(\"ner_label == {}\".format(list(vocs[\"ner_label\"]).index(c[\"pathologie\"]))), prefix=prefix+\"pathologie_\"),\n",
    "    }\n",
    "    for name, query in queries.items():\n",
    "        metrics.update(compute_metrics(merged.query(query), prefix=prefix+name+\"_\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To debug the training, we can just comment the \"def run_epoch()\" and execute the function body manually without changing anything to it\n",
    "def extract_mentions(batcher, all_nets, max_depth=10):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    batcher: Batcher \n",
    "        The batcher containing the text from which we want to extract the mentions (and maybe the gold mentions)\n",
    "    ner_net: torch.nn.Module\n",
    "    max_depth: int\n",
    "        Max number of times we run the model per sample\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    pred_batches = []\n",
    "    n_mentions = 0\n",
    "    ner_net = all_nets[\"ner_net\"]\n",
    "    tag_embeddings = all_nets[\"tag_embeddings\"]\n",
    "    with evaluating(all_nets):\n",
    "        with torch.no_grad():\n",
    "            for batch_i, batch in enumerate(batcher['sentence'].dataloader(batch_size=batch_size, shuffle=False, sparse_sort_on=\"token_mask\", device=tg.device)):\n",
    "\n",
    "                tag_embeds = torch.zeros(*batch[\"sentence\", \"token\"].shape[:2], tag_dim, device=tg.device)\n",
    "                current_sentences_idx = torch.arange(len(batch), device=tg.device)\n",
    "                mask = batch[\"token_mask\"]\n",
    "                tokens = batch[\"token\"]\n",
    "\n",
    "                for i in range(max_depth):\n",
    "                    # Run the model argmax here\n",
    "                    ner_res = ner_net(\n",
    "                        tokens = tokens,\n",
    "                        mask = mask,\n",
    "                        tag_embeds = tag_embeds,\n",
    "                        return_embeddings=True\n",
    "                    )\n",
    "\n",
    "                    # Run the linear CRF Viterbi algorithm to compute the most likely sequence\n",
    "                    pred_tags = ner_net.crf.decode(ner_res[\"scores\"], mask)\n",
    "                    spans = ner_net.crf.tags_to_spans(pred_tags, mask)\n",
    "\n",
    "                    # Save predicted mentions\n",
    "                    pred_batch = Batcher({\n",
    "                        \"mention\": {\n",
    "                            \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans[\"span_doc_id\"]), device=tg.device),\n",
    "                            \"begin\": spans[\"span_begin\"],\n",
    "                            \"end\": spans[\"span_end\"],\n",
    "                            \"ner_label\": spans[\"span_label\"],\n",
    "                            \"@sentence_id\": current_sentences_idx[spans[\"span_doc_id\"]],\n",
    "                            \"depth\": torch.full_like(spans[\"span_begin\"], fill_value=i),\n",
    "                        },\n",
    "                        \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                        \"doc\": dict(batch[\"doc\"])}, \n",
    "                        check=False).sparsify()\n",
    "                    pred_batches.append(pred_batch)\n",
    "                    n_mentions += len(spans[\"span_doc_id\"])\n",
    "\n",
    "                    non_empty_sentences = torch.unique(spans[\"span_doc_id\"])\n",
    "\n",
    "                    if len(non_empty_sentences) == 0:\n",
    "                        break\n",
    "\n",
    "                    # Convert the predicted spans to tags using the same encoding scheme as the one used to decode predicted tags\n",
    "                    # (We could use a different one: BIODecoder/BIOULDecoder.spans_to_tags is a static function)\n",
    "                    feature_tags = ner_net.crf.spans_to_tags(\n",
    "                        torch.arange(len(spans[\"span_begin\"]), device=spans[\"span_begin\"].device),\n",
    "                        spans[\"span_begin\"], \n",
    "                        spans[\"span_end\"],\n",
    "                        spans[\"span_label\"], \n",
    "                        n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                        n_samples=len(spans[\"span_begin\"]),\n",
    "                    )\n",
    "                    tag_mention, tag_positions = feature_tags.nonzero(as_tuple=True)\n",
    "                    tag_sentence = spans[\"span_doc_id\"][tag_mention]\n",
    "                    tag_values = feature_tags[tag_mention, tag_positions]\n",
    "\n",
    "                    tag_embeds = tag_embeds.view(-1, tag_dim).index_add_(\n",
    "                        dim=0,\n",
    "                        index=tag_sentence * batch[\"sentence\", \"token\"].shape[1] + tag_positions, \n",
    "                        source=tag_embeddings.weight[tag_values-1]).view(len(current_sentences_idx), batch[\"sentence\", \"token\"].shape[1], tag_dim)[non_empty_sentences]\n",
    "\n",
    "                    # Compute the tokens label tag embeddings of the observed (maybe overlapping) mentions\n",
    "                    tokens = tokens[non_empty_sentences]\n",
    "                    mask = mask[non_empty_sentences]\n",
    "                    current_sentences_idx = current_sentences_idx[non_empty_sentences]\n",
    "    return Batcher.concat(pred_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Define the training metrics\n",
    "metrics_info = defaultdict(lambda: False)\n",
    "flt_format = (5, \"{:.4f}\".format)\n",
    "metrics_info.update({\n",
    "    \"train_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"train_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    #\"train_recall\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_rec\"},\n",
    "    #\"train_precision\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_prec\"},\n",
    "    \"train_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"train_f1\"},\n",
    "    \n",
    "    \"val_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_ner_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \"val_label_loss\": {\"goal\": 0, \"format\": flt_format},\n",
    "    \n",
    "    \"val_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_f1\"},\n",
    "    \"val_3.1_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.1_f1\"},\n",
    "    \"val_3.2_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_3.2_f1\"},\n",
    "    \"val_macro_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_macro_f1\"},\n",
    "    \"val_sosy_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_sosy_f1\"},\n",
    "    \"val_pathologie_f1\": {\"goal\": 1, \"format\": flt_format, \"name\": \"val_patho_f1\"},\n",
    "    \n",
    "    \"duration\": {\"format\": flt_format, \"name\": \"   dur(s)\"},\n",
    "    \"rescale\": {\"format\": flt_format},\n",
    "    \"n_depth\": {\"format\": flt_format},\n",
    "    \"n_matched\": {\"format\": flt_format},\n",
    "    \"n_targets\": {\"format\": flt_format},\n",
    "    \"n_observed\": {\"format\": flt_format},\n",
    "    \"total_score_sum\": {\"format\": flt_format},\n",
    "    \"lr\": {\"format\": (5, \"{:.2e}\".format)},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batcher(docs, sentences, zones, mentions, conflicts, tokens):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    docs: pd.DataFrame\n",
    "    sentences: pd.DataFrame\n",
    "    zones: pd.DataFrame\n",
    "    mentions: pd.DataFrame\n",
    "    conflicts: pd.DataFrame\n",
    "    tokens: pd.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Batcher\n",
    "    \"\"\"\n",
    "    docs = docs.copy()\n",
    "    sentences = sentences.copy()\n",
    "    zones = zones.copy()\n",
    "    mentions = mentions.copy()\n",
    "    conflicts = conflicts.copy()\n",
    "    tokens = tokens.copy()\n",
    "    \n",
    "    [tokens[\"token_id\"]], unique_token_id = factorize_rows([tokens[\"token_id\"]])\n",
    "    [mentions[\"mention_id\"], conflicts[\"mention_id\"], conflicts[\"mention_id_other\"]], unique_mention_ids = factorize_rows(\n",
    "        [mentions[[\"doc_id\", \"sentence_id\", \"mention_id\"]], conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]])\n",
    "    [zones[\"zone_id\"], mentions[\"zone_id\"]], unique_zone_ids = factorize_rows(\n",
    "        [zones[[\"doc_id\", \"sentence_id\", \"zone_id\"]], mentions[[\"doc_id\", \"sentence_id\", \"zone_id\"]]])\n",
    "    [sentences[\"sentence_id\"], zones[\"sentence_id\"], mentions[\"sentence_id\"], tokens[\"sentence_id\"],], unique_sentence_ids = factorize_rows(\n",
    "        [sentences[[\"doc_id\", \"sentence_id\"]], zones[[\"doc_id\", \"sentence_id\"]], mentions[[\"doc_id\", \"sentence_id\"]], tokens[[\"doc_id\", \"sentence_id\"]]])\n",
    "    [docs[\"doc_id\"], sentences[\"doc_id\"], zones[\"doc_id\"], mentions[\"doc_id\"], tokens[\"doc_id\"]], unique_doc_ids = factorize_rows(\n",
    "        [docs[\"doc_id\"], sentences[\"doc_id\"], zones[\"doc_id\"], mentions[\"doc_id\"], tokens[\"doc_id\"]])\n",
    "    \n",
    "    batcher = Batcher({\n",
    "        \"mention\": {\n",
    "            \"mention_id\": mentions[\"mention_id\"],\n",
    "            \"zone_id\": mentions[\"zone_id\"],\n",
    "            \"sentence_id\": mentions[\"sentence_id\"],\n",
    "            \"doc_id\": mentions[\"doc_id\"],\n",
    "            \"begin\": mentions[\"begin\"],\n",
    "            \"end\": mentions[\"end\"],\n",
    "            \"ner_label\": mentions[\"ner_label\"].cat.codes,\n",
    "            \"conflict_mention_id\": df_to_csr(conflicts[\"mention_id\"], conflicts[\"conflict_idx\"], conflicts[\"mention_id_other\"], n_rows=len(unique_mention_ids)),\n",
    "            \"conflict_mask\": df_to_csr(conflicts[\"mention_id\"], conflicts[\"conflict_idx\"], n_rows=len(unique_mention_ids)),\n",
    "        },\n",
    "        \"zone\": {\n",
    "            \"zone_id\": zones[\"zone_id\"],\n",
    "            \"sentence_id\": zones[\"sentence_id\"],\n",
    "            \"doc_id\": zones[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"zone_id\"], mentions[\"zone_mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_zone_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"zone_id\"], mentions[\"zone_mention_idx\"], n_rows=len(unique_zone_ids)),\n",
    "        },\n",
    "        \"sentence\": {\n",
    "            \"sentence_id\": sentences[\"sentence_id\"],\n",
    "            \"doc_id\": sentences[\"doc_id\"],\n",
    "            \"mention_id\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], mentions[\"mention_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"mention_mask\": df_to_csr(mentions[\"sentence_id\"], mentions[\"mention_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"token\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], tokens[\"token\"].cat.codes, n_rows=len(unique_sentence_ids)),\n",
    "            \"token_mask\": df_to_csr(tokens[\"sentence_id\"], tokens[\"token_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"zone_id\": df_to_csr(zones[\"sentence_id\"], zones[\"zone_idx\"], zones[\"zone_id\"], n_rows=len(unique_sentence_ids)),\n",
    "            \"zone_mask\": df_to_csr(zones[\"sentence_id\"], zones[\"zone_idx\"], n_rows=len(unique_sentence_ids)),\n",
    "        },\n",
    "        \"doc\": {\n",
    "            \"doc_id\": np.arange(len(unique_doc_ids)),\n",
    "            \"sentence_id\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], sentences[\"sentence_id\"], n_rows=len(unique_doc_ids)),\n",
    "            \"sentence_mask\": df_to_csr(sentences[\"doc_id\"], sentences[\"sentence_idx\"], n_rows=len(unique_doc_ids)),\n",
    "            \"split\": docs[\"split\"].cat.codes,\n",
    "        }},\n",
    "        masks={\"sentence\": {\"token\": \"token_mask\", \"zone_id\": \"zone_mask\", \"mention_id\": \"mention_mask\"}, \n",
    "               \"mention\": {\"conflict_mention_id\": \"conflict_mask\"},\n",
    "               \"zone\": {\"mention_id\": \"mention_mask\"}, \n",
    "               \"doc\": {\"sentence_id\": \"sentence_mask\"}}\n",
    "    )\n",
    "    return (\n",
    "        batcher, \n",
    "        dict(docs=docs, sentences=sentences, zones=zones, mentions=mentions, tokens=tokens),\n",
    "        dict(token_id=unique_token_id, mention_id=unique_mention_ids, zone_id=unique_zone_ids, sentence_id=unique_sentence_ids, doc_id=unique_doc_ids)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_labels,\n",
    "                 hidden_dim,\n",
    "                 dropout,\n",
    "                 n_tokens=None,\n",
    "                 token_dim=None,\n",
    "                 embeddings=None,\n",
    "                 tag_scheme=\"bio\",\n",
    "                 metric='linear',\n",
    "                 metric_fc_kwargs=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        if embeddings is not None:\n",
    "            self.embeddings = embeddings\n",
    "            if n_tokens is None or token_dim is None:\n",
    "                if hasattr(embeddings, 'weight'):\n",
    "                    n_tokens, token_dim = embeddings.weight.shape\n",
    "                else:\n",
    "                    n_tokens, token_dim = embeddings.embeddings.weight.shape\n",
    "        else:\n",
    "            self.embeddings = torch.nn.Embedding(n_tokens, token_dim) if n_tokens > 0 else None\n",
    "        assert token_dim is not None, \"Provide token_dim or embeddings\"\n",
    "        assert self.embeddings is not None\n",
    "\n",
    "        dim = (token_dim if n_tokens > 0 else 0)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        if tag_scheme == \"bio\":\n",
    "            self.crf = BIODecoder(n_labels)\n",
    "        elif tag_scheme == \"bioul\":\n",
    "            self.crf = BIOULDecoder(n_labels)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = dim\n",
    "        self.linear = torch.nn.Linear(dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        n_tags = self.crf.num_tags\n",
    "        metric_fc_kwargs = metric_fc_kwargs if metric_fc_kwargs is not None else {}\n",
    "        if metric == \"linear\":\n",
    "            self.metric_fc = torch.nn.Linear(dim, n_tags)\n",
    "        elif metric == \"cosine\":\n",
    "            self.metric_fc = CosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        elif metric == \"ema_cosine\":\n",
    "            self.metric_fc = EMACosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        else:\n",
    "            raise Exception()\n",
    "    \n",
    "    def extended_embeddings(self, tokens, mask, **kwargs):\n",
    "        # Default case here, size <= 512\n",
    "        # Small ugly check to see if self.embeddings is Bert-like, then we need to pass a mask\n",
    "        if hasattr(self.embeddings, 'encoder') or hasattr(self.embeddings, 'transformer'):\n",
    "            return self.embeddings(tokens, mask, **kwargs)[0]\n",
    "        else:\n",
    "            return self.embeddings(tokens)\n",
    "\n",
    "    def forward(self, tokens, mask, tag_embeds=None, return_embeddings=False):\n",
    "        # Embed the tokens\n",
    "        scores = None\n",
    "        # shape: n_batch * sequence * 768\n",
    "        embeds = self.extended_embeddings(tokens, mask, custom_embeds=tag_embeds)\n",
    "        state = embeds.masked_fill(~mask.unsqueeze(-1), 0)\n",
    "        state = torch.relu(self.linear(self.dropout(state)))# + state\n",
    "        state = self.batch_norm(state.view(-1, state.shape[-1])).view(state.shape)\n",
    "        scores = self.metric_fc(state)\n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"embeddings\": embeds if return_embeddings else None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNERNet(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_labels,\n",
    "                 hidden_dim,\n",
    "                 dropout,\n",
    "                 n_tokens=None,\n",
    "                 token_dim=None,\n",
    "                 embeddings=None,\n",
    "                 tag_scheme=\"bio\",\n",
    "                 metric='linear',\n",
    "                 metric_fc_kwargs=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        if embeddings is not None:\n",
    "            self.embeddings = embeddings\n",
    "            if n_tokens is None or token_dim is None:\n",
    "                if hasattr(embeddings, 'weight'):\n",
    "                    n_tokens, token_dim = embeddings.weight.shape\n",
    "                else:\n",
    "                    n_tokens, token_dim = embeddings.embeddings.weight.shape\n",
    "        else:\n",
    "            self.embeddings = torch.nn.Embedding(n_tokens, token_dim) if n_tokens > 0 else None\n",
    "        assert token_dim is not None, \"Provide token_dim or embeddings\"\n",
    "        assert self.embeddings is not None\n",
    "\n",
    "        dim = (token_dim if n_tokens > 0 else 0)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        if tag_scheme == \"bio\":\n",
    "            self.crf = BIODecoder(n_labels)\n",
    "        elif tag_scheme == \"bioul\":\n",
    "            self.crf = BIOULDecoder(n_labels)\n",
    "        else:\n",
    "            raise Exception()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = dim\n",
    "        self.linear = torch.nn.Linear(dim, hidden_dim)\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(dim)\n",
    "        self.lstm = torch.nn.LSTM(hidden_dim, \n",
    "                                  hidden_dim, dropout=dropout, batch_first=True, num_layers=2, bidirectional=True)\n",
    "            \n",
    "\n",
    "        n_tags = self.crf.num_tags\n",
    "        metric_fc_kwargs = metric_fc_kwargs if metric_fc_kwargs is not None else {}\n",
    "        if metric == \"linear\":\n",
    "            self.metric_fc = torch.nn.Linear(hidden_dim*2, n_tags)\n",
    "        elif metric == \"cosine\":\n",
    "            self.metric_fc = CosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        elif metric == \"ema_cosine\":\n",
    "            self.metric_fc = EMACosineSimilarity(dim, n_tags, rescale=rescale, **metric_fc_kwargs)\n",
    "        else:\n",
    "            raise Exception()\n",
    "    \n",
    "    def extended_embeddings(self, tokens, mask, **kwargs):\n",
    "        # Default case here, size <= 512\n",
    "        # Small ugly check to see if self.embeddings is Bert-like, then we need to pass a mask\n",
    "        if hasattr(self.embeddings, 'encoder') or hasattr(self.embeddings, 'transformer'):\n",
    "            return self.embeddings(tokens, mask, **kwargs)[0]\n",
    "        else:\n",
    "            return self.embeddings(tokens)\n",
    "\n",
    "    def forward(self, tokens, mask, tag_embeds=None, return_embeddings=False):\n",
    "        # Embed the tokens\n",
    "        scores = None\n",
    "        # shape: n_batch * sequence * 768\n",
    "        embeds = self.extended_embeddings(tokens, mask, custom_embeds=tag_embeds)\n",
    "        state = embeds.masked_fill(~mask.unsqueeze(-1), 0)\n",
    "        state = torch.relu(self.linear(self.dropout(state)))# + state\n",
    "        state = self.batch_norm(state.view(-1, state.shape[-1])).view(state.shape)\n",
    "        \n",
    "        lstm_state = self.lstm(self.dropout(state))[0]\n",
    "        state = torch.relu(lstm_state)\n",
    "        scores = self.metric_fc(state)\n",
    "        return {\n",
    "            \"scores\": scores,\n",
    "            \"embeddings\": embeds if return_embeddings else None,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@cached\n",
    "def preprocess(\n",
    "    dataset,\n",
    "    max_sentence_length,\n",
    "    bert_name,\n",
    "    ner_labels=None,\n",
    "    unknown_labels=\"drop\",\n",
    "    vocabularies=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        dataset: Dataset\n",
    "        max_sentence_length: int\n",
    "            Max number of \"words\" as defined by the regex in regex_sentencize (so this is not the nb of wordpieces)\n",
    "        bert_name: str\n",
    "            bert path/name\n",
    "        ner_labels: list of str \n",
    "            allowed ner labels (to be dropped or filtered)\n",
    "        unknown_labels: str\n",
    "            \"drop\" or \"raise\"\n",
    "        vocabularies: dict[str; np.ndarray or list]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, dict[str; np.ndarray or list])\n",
    "        docs:      ('split', 'text', 'doc_id')\n",
    "        sentences: ('split', 'doc_id', 'sentence_idx', 'begin', 'end', 'text', 'sentence_id')\n",
    "        zones:     ('doc_id', 'sentence_id', 'zone_id', 'zone_idx')\n",
    "        mentions:  ('ner_label', 'doc_id', 'sentence_id', 'mention_id', 'depth', 'zone_id', 'text', 'mention_idx', 'begin', 'end', 'zone_mention_idx')\n",
    "        conflicts: ('doc_id', 'sentence_id', 'mention_id', 'mention_id_other', 'conflict_idx')\n",
    "        tokens:    ('split', 'token', 'sentence_id', 'token_id', 'token_idx', 'begin', 'end', 'doc_id', 'sentence_idx')\n",
    "        deltas:    ('doc_id', 'begin', 'end', 'delta')\n",
    "        vocs: vocabularies to be reused later for encoding more data or decoding predictions\n",
    "    \"\"\"\n",
    "    print(\"Dataset:\", dataset)\n",
    "\n",
    "    mentions = dataset[\"mentions\"].rename({\"label\": \"ner_label\"}, axis=1)\n",
    "\n",
    "    \n",
    "    if ner_labels is not None:\n",
    "        len_before = len(mentions)\n",
    "        unknown_ner_labels = list(mentions[~mentions[\"ner_label\"].isin(ner_labels)][\"ner_label\"].drop_duplicates())\n",
    "        mentions = mentions[mentions[\"ner_label\"].isin(ner_labels)]\n",
    "        \n",
    "        if len(unknown_ner_labels) and unknown_labels == \"raise\":\n",
    "            raise Exception(f\"Unkown labels in {len_before-len(mentions)} mentions: \", unknown_ner_labels)\n",
    "\n",
    "    # Check that there is no mention overlap\n",
    "    mentions = mentions.merge(dataset[\"fragments\"].groupby([\"doc_id\", \"mention_id\"], as_index=False, observed=True).agg({\"begin\": \"min\", \"end\": \"max\"}))\n",
    "\n",
    "    \n",
    "    print(\"Transform texts...\", end=\" \")\n",
    "    transformed_docs, deltas = apply_substitutions(\n",
    "        dataset[\"docs\"], *zip(\n",
    "            (r\"(?<=[{}\\\\])(?![ ])\".format(string.punctuation), r\" \"),\n",
    "            (r\"(?<![ ])(?=[{}\\\\])\".format(string.punctuation), r\" \"),\n",
    "            (\"(?<=[a-zA-Z])(?=[0-9])\", r\" \"),\n",
    "            (\"(?<=[0-9])(?=[A-Za-z])\", r\" \"),\n",
    "        ), apply_unidecode=True)\n",
    "    transformed_docs = transformed_docs.astype({\"text\": str})\n",
    "    transformed_mentions = apply_deltas(mentions, deltas, on=['doc_id'])\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Splitting into sentences...\", end=\" \")\n",
    "    sentences = regex_sentencize(\n",
    "        transformed_docs, \n",
    "        reg_split=r\"((?:\\s*\\n\\s*\\n)+\\s*|(?:(?<=[a-z0-9)]\\n)|(?<=[a-z0-9)][ ](?:\\.|\\n))|(?<=[a-z0-9)][ ][ ](?:\\.|\\n)))\\s*(?=[A-Z]))\",\n",
    "        min_sentence_length=0, max_sentence_length=max_sentence_length,\n",
    "        # balance_parentheses=True, # default is True\n",
    "    )\n",
    "    \n",
    "    [sentence_mentions], sentences, sentence_to_docs = partition_spans([transformed_mentions], sentences, new_id_name=\"sentence_id\", overlap_policy=False)\n",
    "#     n_sentences_per_mention = sentence_mentions.assign(count=1).groupby([\"doc_id\", \"mention_id\"], as_index=False).agg({\"count\": \"sum\", \"text\": \"first\", \"sentence_id\": \"last\"})\n",
    "#     if n_sentences_per_mention[\"count\"].max() > 1:\n",
    "#         display(n_sentences_per_mention.query(\"count > 1\"))\n",
    "#         display(sentences[sentences[\"sentence_id\"].isin(n_sentences_per_mention.query(\"count > 1\")[\"sentence_id\"])][\"text\"].tolist())\n",
    "#         raise Exception(\"Some mentions could be mapped to more than 1 sentences ({})\".format(n_sentences_per_mention[\"count\"].max()))\n",
    "    if sentence_to_docs is not None:\n",
    "        sentence_mentions = sentence_mentions.merge(sentence_to_docs)\n",
    "        \n",
    "    sentence_mentions = sentence_mentions.assign(mention_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\"], {\"mention_idx\": lambda x: tuple(range(len(x)))})\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Tokenizing...\", end=\" \")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(bert_name)\n",
    "    sentences[\"text\"] = sentences[\"text\"].str.lower()\n",
    "    tokens = huggingface_tokenize(sentences, tokenizer, doc_id_col=\"sentence_id\")\n",
    "    sentence_mentions = split_into_spans(sentence_mentions, tokens, pos_col=\"token_idx\", overlap_policy=False)\n",
    "    print(\"done\")\n",
    "    \n",
    "    print(\"Processing zones (overlapping areas)...\", end=\" \")\n",
    "    # Extract overlapping spans\n",
    "    conflicts = (\n",
    "        merge_with_spans(sentence_mentions, sentence_mentions, on=[\"doc_id\", \"sentence_id\", (\"begin\", \"end\")], how=\"outer\", suffixes=(\"\", \"_other\"))\n",
    "    )\n",
    "\n",
    "    # ids1, and ids2 make the edges of the overlapping mentions of the same type (see the \"ner_label\")\n",
    "    [ids1, ids2], unique_ids = factorize_rows(\n",
    "        [conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\"]], \n",
    "         conflicts[[\"doc_id\", \"sentence_id\", \"mention_id_other\"]]],\n",
    "        sentence_mentions.eval(\"size=(end-begin)\").sort_values(\"size\")[[\"doc_id\", \"sentence_id\", \"mention_id\"]]\n",
    "    )\n",
    "    g = nx.from_scipy_sparse_matrix(df_to_csr(ids1, ids2, n_rows=len(unique_ids), n_cols=len(unique_ids)))\n",
    "    colored_nodes = np.asarray(list(nx.coloring.greedy_color(g, strategy=keep_order).items()))\n",
    "    unique_ids['depth'] = colored_nodes[:, 1][colored_nodes[:, 0].argsort()]\n",
    "    zone_indices, mention_indices = zip(*chain.from_iterable(zip(repeat(zone_idx), zone) for zone_idx, zone in enumerate(nx.connected_components(g))))\n",
    "    conflicts = conflicts[[\"doc_id\", \"sentence_id\", \"mention_id\", \"mention_id_other\"]].assign(conflict_idx=0).nlstruct.groupby_assign([\"doc_id\", \"sentence_id\", \"mention_id\"], {\"conflict_idx\": lambda x: tuple(range(len(x)))})\n",
    "\n",
    "    zone_mentions = pd.DataFrame({\n",
    "        **unique_ids.iloc[list(mention_indices)],\n",
    "        \"zone_id\": zone_indices,\n",
    "    }).merge(sentence_mentions, on=[\"doc_id\", \"sentence_id\", \"mention_id\"]).sort_values([\"doc_id\", \"sentence_id\", \"zone_id\", \"mention_id\"])\n",
    "    zone_mentions = zone_mentions.assign(zone_mention_idx=0).nlstruct.groupby_assign(['doc_id', 'sentence_id', 'zone_id'], {\"zone_mention_idx\": lambda vec: tuple(np.arange(len(vec)))})\n",
    "    sentence_zones = zone_mentions[[\"doc_id\", \"sentence_id\", \"zone_id\"]].drop_duplicates()\n",
    "    sentence_zones = sentence_zones.assign(zone_idx=0).nlstruct.groupby_assign(['doc_id', 'sentence_id'], {\"zone_idx\": lambda vec: tuple(np.arange(len(vec)))})\n",
    "    sentence_mentions = sentence_mentions.merge(zone_mentions.drop_duplicates([\"doc_id\", \"sentence_id\", \"mention_id\", \"depth\"]))\n",
    "    print(\"done\")\n",
    "\n",
    "    print(\"Computing vocabularies...\")\n",
    "    [transformed_docs, sentences, sentence_zones, zone_mentions, tokens], vocs = normalize_vocabularies(\n",
    "        [transformed_docs, sentences, sentence_zones, zone_mentions, tokens], \n",
    "        vocabularies={\"split\": [\"train\", \"val\", \"test\"]} if vocabularies is None else vocabularies,\n",
    "        train_vocabularies={\"source\": False, \"text\": False} if vocabularies is None else False,\n",
    "        verbose=True)\n",
    "    print(\"done\")\n",
    "    return transformed_docs, sentences, sentence_zones, zone_mentions, conflicts, tokens, deltas, vocs\n",
    "\n",
    "def keep_order(G, colors):\n",
    "    \"\"\"Returns a list of the nodes of ``G`` in ordered identically to their id in the graph\n",
    "    ``G`` is a NetworkX graph. ``colors`` is ignored.\n",
    "    This is to assign a depth using the nx.coloring.greedy_color function\n",
    "    \"\"\"\n",
    "    return sorted(list(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset(\n",
      "  (docs):       3790 * ('doc_id', 'text', 'split')\n",
      "  (mentions):    926 * ('doc_id', 'mention_id', 'label', 'text')\n",
      "  (fragments):   926 * ('doc_id', 'mention_id', 'fragment_id', 'begin', 'end')\n",
      "  (attributes):    0 * ('doc_id', 'mention_id', 'attribute_id', 'label', 'value')\n",
      "  (relations):     0 * ('doc_id', 'relation_id', 'relation_label', 'from_mention_id', 'to_mention_id')\n",
      "  (comments):      0 * ('doc_id', 'comment_id', 'mention_id', 'comment')\n",
      ")\n",
      "Transform texts... done\n",
      "Splitting into sentences... done\n",
      "Tokenizing... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tannier/anaconda3/envs/yt_nlp/lib/python3.7/site-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.\n",
      "  category=FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Processing zones (overlapping areas)... done\n",
      "Computing vocabularies...\n",
      "Will train vocabulary for ner_label\n",
      "Will train vocabulary for token\n",
      "Discovered existing vocabulary (32005 entities) for token\n",
      "Normalized text, with given vocabulary and no unk\n",
      "Normalized text, with given vocabulary and no unk\n",
      "Normalized text, with given vocabulary and no unk\n",
      "Normalized split, with given vocabulary and no unk\n",
      "Normalized split, with given vocabulary and no unk\n",
      "Normalized split, with given vocabulary and no unk\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "bert_name = \"camembert-base\"\n",
    "dataset = load_from_brat('/home/tannier/data/resources/daloux/brat_files')#load_genia_ner()\n",
    "\n",
    "NEG_ONLY = False\n",
    "\n",
    "if NEG_ONLY:\n",
    "    neg_doc_ids = dataset['mentions']['doc_id'].unique()\n",
    "    neg_docs = dataset['docs'][dataset['docs']['doc_id'].isin(neg_doc_ids)]\n",
    "    neg_mentions = dataset['mentions'][dataset['mentions']['doc_id'].isin(neg_doc_ids)]\n",
    "    neg_fragments = dataset['fragments'][dataset['fragments']['doc_id'].isin(neg_doc_ids)]\n",
    "    \n",
    "    dataset = Dataset(\n",
    "        docs=neg_docs,\n",
    "        mentions=neg_mentions,\n",
    "        fragments=neg_fragments,\n",
    "        attributes=dataset['attributes'],\n",
    "        relations=dataset['relations'],\n",
    "        comments=dataset['comments'],\n",
    "    )\n",
    "\n",
    "docs, sentences, zones, mentions, conflicts, tokens, deltas, vocs = preprocess(\n",
    "    dataset=dataset,\n",
    "    max_sentence_length=120,\n",
    "    bert_name=bert_name,\n",
    "    ner_labels= ['NEG'],\n",
    "    unknown_labels=\"drop\",\n",
    ")\n",
    "batcher, encoded, ids = make_batcher(docs, sentences, zones, mentions, conflicts, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (L2 dist) between train and val frequencies: 0.0\n",
      "Frequencies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NEG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  NEG\n",
       "0  train  1.0\n",
       "1    val  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all_test_doc_ids = []\n",
    "#sims = {}\n",
    "#for i in range(200):\n",
    "seed_all(1234567+137)\n",
    "\n",
    "train_batcher = batcher['doc'][batcher['doc']['split']==0]['sentence']\n",
    "test_batcher = batcher['doc'][batcher['doc']['split']==2]['sentence']\n",
    "\n",
    "splits = np.zeros(len(train_batcher['doc']), dtype=int)\n",
    "\n",
    "val_perc = 0.1\n",
    "splits[np.random.choice(np.arange(len(splits)), size=int(val_perc * len(splits)))] = 1\n",
    "\n",
    "val_batcher = batcher['sentence'][splits == 1]\n",
    "\n",
    "# train_val_split = np.random.permutation(len(train_batcher))\n",
    "# test_batcher = train_batcher[train_val_split[:int(0.1*len(train_val_split))]]['sentence']\n",
    "# train_batcher = train_batcher[train_val_split[int(0.1*len(train_val_split)):]]['sentence']\n",
    "sim = ((np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention']) -\n",
    "np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention']))**2).sum()\n",
    "print(\"Similarity (L2 dist) between train and val frequencies:\", sim)\n",
    "print(\"Frequencies\")\n",
    "#all_test_doc_ids.append((test_doc_ids, sim))\n",
    "display(pd.DataFrame([\n",
    "    {\"index\": \"train\", **dict(zip(vocs[\"ner_label\"], np.bincount(train_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(train_batcher['mention'])))},\n",
    "    {\"index\": \"val\", **dict(zip(vocs[\"ner_label\"], np.bincount(val_batcher['mention', 'ner_label'], minlength=len(vocs[\"ner_label\"]))/len(val_batcher['mention'])))},\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install /home/yoann/these/DEFT/nlstruct/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices 8\n",
      "Current device cuda:1\n",
      "3 768 bioul 12 0.01 4e-05 1 0.1\n",
      "before layer norm\n",
      "Using cache /home/tannier/data/cache/daloux/2bb9f55995f7f9f3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tannier/anaconda3/envs/yt_nlp/lib/python3.7/site-packages/nlstruct/train/helpers.py:138: UserWarning: Entry 'schedules' in the state seems to be mutable but has no load_state_dict/state_dict methods. This could lead to unpredictable behaviors.\n",
      "  warn(f\"Entry '{key}' in the state seems to be mutable but has no load_state_dict/state_dict methods. This could lead to unpredictable behaviors.\")\n",
      "100%|██████████| 49/49 [00:29<00:00,  1.66it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "epoch | train_ner_loss | train_f1 | \u001b[31mval_f1\u001b[0m | val_3.1_f1 | val_macro_f1 | n_matched |       lr |    dur(s)\n",
      "    1 |         \u001b[32m7.2745\u001b[0m |   \u001b[32m0.0040\u001b[0m | \u001b[32m0.0000\u001b[0m |     \u001b[32m0.0000\u001b[0m |       \u001b[32m0.0000\u001b[0m |  356.0000 | 1.00e-02 |   31.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2 |         \u001b[32m2.9660\u001b[0m |   \u001b[32m0.0537\u001b[0m | \u001b[31m0.0000\u001b[0m |     \u001b[31m0.0000\u001b[0m |       \u001b[31m0.0000\u001b[0m |  372.0000 | 1.00e-02 |   18.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:21<00:00,  2.31it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3 |         \u001b[32m2.4525\u001b[0m |   \u001b[32m0.0750\u001b[0m | \u001b[32m0.0870\u001b[0m |     \u001b[32m0.0870\u001b[0m |       \u001b[32m0.0870\u001b[0m |  372.0000 | 1.00e-02 |   22.5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4 |         \u001b[32m1.7418\u001b[0m |   \u001b[32m0.1553\u001b[0m | \u001b[31m0.0000\u001b[0m |     \u001b[31m0.0000\u001b[0m |       \u001b[31m0.0000\u001b[0m |  338.0000 | 1.00e-02 |   18.3814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5 |         \u001b[32m1.3981\u001b[0m |   \u001b[32m0.2202\u001b[0m | \u001b[32m0.3932\u001b[0m |     \u001b[32m0.3932\u001b[0m |       \u001b[32m0.3932\u001b[0m |  393.0000 | 1.00e-02 |   18.9467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 |         \u001b[32m1.1315\u001b[0m |   \u001b[32m0.2599\u001b[0m | \u001b[31m0.3299\u001b[0m |     \u001b[31m0.3299\u001b[0m |       \u001b[31m0.3299\u001b[0m |  387.0000 | 1.00e-02 |   18.9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7 |         \u001b[32m0.9462\u001b[0m |   \u001b[32m0.3194\u001b[0m | \u001b[31m0.3444\u001b[0m |     \u001b[31m0.3444\u001b[0m |       \u001b[31m0.3444\u001b[0m |  381.0000 | 1.00e-02 |   18.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:19<00:00,  2.51it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8 |         \u001b[32m0.7878\u001b[0m |   \u001b[32m0.3742\u001b[0m | \u001b[31m0.0000\u001b[0m |     \u001b[31m0.0000\u001b[0m |       \u001b[31m0.0000\u001b[0m |  350.0000 | 1.00e-02 |   20.6121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9 |         \u001b[32m0.7805\u001b[0m |   \u001b[31m0.3683\u001b[0m | \u001b[31m0.3575\u001b[0m |     \u001b[31m0.3575\u001b[0m |       \u001b[31m0.3575\u001b[0m |  356.0000 | 1.00e-02 |   18.7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10 |         \u001b[32m0.6293\u001b[0m |   \u001b[32m0.4261\u001b[0m | \u001b[32m0.4878\u001b[0m |     \u001b[32m0.4878\u001b[0m |       \u001b[32m0.4878\u001b[0m |  357.0000 | 1.00e-02 |   18.8671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 |         \u001b[32m0.5590\u001b[0m |   \u001b[32m0.4467\u001b[0m | \u001b[31m0.3148\u001b[0m |     \u001b[31m0.3148\u001b[0m |       \u001b[31m0.3148\u001b[0m |  367.0000 | 1.00e-02 |   18.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 |         \u001b[32m0.4646\u001b[0m |   \u001b[32m0.5233\u001b[0m | \u001b[32m0.5806\u001b[0m |     \u001b[32m0.5806\u001b[0m |       \u001b[32m0.5806\u001b[0m |  366.0000 | 1.00e-02 |   18.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 |         \u001b[32m0.4132\u001b[0m |   \u001b[31m0.5166\u001b[0m | \u001b[32m0.7097\u001b[0m |     \u001b[32m0.7097\u001b[0m |       \u001b[32m0.7097\u001b[0m |  387.0000 | 1.00e-02 |   18.8515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14 |         \u001b[32m0.4065\u001b[0m |   \u001b[32m0.5422\u001b[0m | \u001b[31m0.4158\u001b[0m |     \u001b[31m0.4158\u001b[0m |       \u001b[31m0.4158\u001b[0m |  389.0000 | 1.00e-02 |   18.4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 |         \u001b[32m0.3730\u001b[0m |   \u001b[32m0.5479\u001b[0m | \u001b[31m0.6719\u001b[0m |     \u001b[31m0.6719\u001b[0m |       \u001b[31m0.6719\u001b[0m |  358.0000 | 1.00e-02 |   18.7271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   16 |         \u001b[32m0.2995\u001b[0m |   \u001b[32m0.6304\u001b[0m | \u001b[31m0.5686\u001b[0m |     \u001b[31m0.5686\u001b[0m |       \u001b[31m0.5686\u001b[0m |  380.0000 | 1.00e-02 |   18.7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   17 |         \u001b[31m0.3161\u001b[0m |   \u001b[31m0.5978\u001b[0m | \u001b[31m0.6667\u001b[0m |     \u001b[31m0.6667\u001b[0m |       \u001b[31m0.6667\u001b[0m |  340.0000 | 1.00e-02 |   18.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 |         \u001b[31m0.3320\u001b[0m |   \u001b[31m0.5481\u001b[0m | \u001b[31m0.6222\u001b[0m |     \u001b[31m0.6222\u001b[0m |       \u001b[31m0.6222\u001b[0m |  358.0000 | 1.00e-02 |   18.8332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 |         \u001b[31m0.3165\u001b[0m |   \u001b[31m0.6156\u001b[0m | \u001b[32m0.7368\u001b[0m |     \u001b[32m0.7368\u001b[0m |       \u001b[32m0.7368\u001b[0m |  375.0000 | 1.00e-02 |   18.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 |         \u001b[32m0.2650\u001b[0m |   \u001b[32m0.6716\u001b[0m | \u001b[31m0.5735\u001b[0m |     \u001b[31m0.5735\u001b[0m |       \u001b[31m0.5735\u001b[0m |  357.0000 | 1.00e-02 |   18.5396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 |         \u001b[32m0.2509\u001b[0m |   \u001b[32m0.6779\u001b[0m | \u001b[32m0.7581\u001b[0m |     \u001b[32m0.7581\u001b[0m |       \u001b[32m0.7581\u001b[0m |  368.0000 | 1.00e-02 |   18.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   22 |         \u001b[31m0.2736\u001b[0m |   \u001b[32m0.6953\u001b[0m | \u001b[31m0.1429\u001b[0m |     \u001b[31m0.1429\u001b[0m |       \u001b[31m0.1429\u001b[0m |  353.0000 | 1.00e-02 |   18.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 |         \u001b[31m0.2941\u001b[0m |   \u001b[31m0.6435\u001b[0m | \u001b[31m0.6885\u001b[0m |     \u001b[31m0.6885\u001b[0m |       \u001b[31m0.6885\u001b[0m |  373.0000 | 1.00e-02 |   18.9003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   24 |         \u001b[32m0.1920\u001b[0m |   \u001b[32m0.7570\u001b[0m | \u001b[32m0.7840\u001b[0m |     \u001b[32m0.7840\u001b[0m |       \u001b[32m0.7840\u001b[0m |  387.0000 | 1.00e-02 |   18.5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 |         \u001b[32m0.1487\u001b[0m |   \u001b[31m0.7564\u001b[0m | \u001b[32m0.8430\u001b[0m |     \u001b[32m0.8430\u001b[0m |       \u001b[32m0.8430\u001b[0m |  361.0000 | 1.00e-02 |   18.9263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26 |         \u001b[31m0.1557\u001b[0m |   \u001b[32m0.7870\u001b[0m | \u001b[31m0.8387\u001b[0m |     \u001b[31m0.8387\u001b[0m |       \u001b[31m0.8387\u001b[0m |  363.0000 | 1.00e-02 |   18.5177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   27 |         \u001b[32m0.1308\u001b[0m |   \u001b[32m0.7878\u001b[0m | \u001b[31m0.3596\u001b[0m |     \u001b[31m0.3596\u001b[0m |       \u001b[31m0.3596\u001b[0m |  368.0000 | 1.00e-02 |   18.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   28 |         \u001b[31m0.1461\u001b[0m |   \u001b[32m0.8017\u001b[0m | \u001b[31m0.8095\u001b[0m |     \u001b[31m0.8095\u001b[0m |       \u001b[31m0.8095\u001b[0m |  356.0000 | 1.00e-02 |   18.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29 |         \u001b[31m0.1710\u001b[0m |   \u001b[31m0.7947\u001b[0m | \u001b[32m0.8480\u001b[0m |     \u001b[32m0.8480\u001b[0m |       \u001b[32m0.8480\u001b[0m |  384.0000 | 1.00e-02 |   18.6477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   30 |         \u001b[32m0.1131\u001b[0m |   \u001b[32m0.8138\u001b[0m | \u001b[31m0.6456\u001b[0m |     \u001b[31m0.6456\u001b[0m |       \u001b[31m0.6456\u001b[0m |  370.0000 | 1.00e-02 |   18.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.84it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   31 |         \u001b[31m0.1147\u001b[0m |   \u001b[32m0.8376\u001b[0m | \u001b[32m0.8527\u001b[0m |     \u001b[32m0.8527\u001b[0m |       \u001b[32m0.8527\u001b[0m |  357.0000 | 1.00e-02 |   18.4835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32 |         \u001b[31m0.1139\u001b[0m |   \u001b[32m0.8427\u001b[0m | \u001b[31m0.8197\u001b[0m |     \u001b[31m0.8197\u001b[0m |       \u001b[31m0.8197\u001b[0m |  350.0000 | 1.00e-02 |   18.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33 |         \u001b[32m0.0715\u001b[0m |   \u001b[32m0.9106\u001b[0m | \u001b[32m0.8769\u001b[0m |     \u001b[32m0.8769\u001b[0m |       \u001b[32m0.8769\u001b[0m |  369.0000 | 1.00e-02 |   18.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   34 |         \u001b[32m0.0613\u001b[0m |   \u001b[32m0.9188\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  367.0000 | 1.00e-02 |   18.8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:08,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   35 |         \u001b[32m0.0585\u001b[0m |   \u001b[32m0.9290\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  377.0000 | 1.00e-02 |   18.8187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   36 |         \u001b[32m0.0517\u001b[0m |   \u001b[32m0.9306\u001b[0m | \u001b[31m0.8750\u001b[0m |     \u001b[31m0.8750\u001b[0m |       \u001b[31m0.8750\u001b[0m |  370.0000 | 1.00e-02 |   18.7164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 |         \u001b[32m0.0360\u001b[0m |   \u001b[32m0.9443\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  379.0000 | 1.00e-02 |   18.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   38 |         \u001b[31m0.0419\u001b[0m |   \u001b[31m0.9313\u001b[0m | \u001b[32m0.9016\u001b[0m |     \u001b[32m0.9016\u001b[0m |       \u001b[32m0.9016\u001b[0m |  365.0000 | 1.00e-02 |   18.8376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39 |         \u001b[31m0.0560\u001b[0m |   \u001b[31m0.9225\u001b[0m | \u001b[31m0.8661\u001b[0m |     \u001b[31m0.8661\u001b[0m |       \u001b[31m0.8661\u001b[0m |  375.0000 | 1.00e-02 |   18.8542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.84it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   40 |         \u001b[31m0.0423\u001b[0m |   \u001b[32m0.9573\u001b[0m | \u001b[31m0.8346\u001b[0m |     \u001b[31m0.8346\u001b[0m |       \u001b[31m0.8346\u001b[0m |  353.0000 | 1.00e-02 |   18.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   41 |         \u001b[31m0.0817\u001b[0m |   \u001b[31m0.8920\u001b[0m | \u001b[31m0.8730\u001b[0m |     \u001b[31m0.8730\u001b[0m |       \u001b[31m0.8730\u001b[0m |  353.0000 | 1.00e-02 |   18.7901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 |         \u001b[31m0.0423\u001b[0m |   \u001b[31m0.9420\u001b[0m | \u001b[31m0.8730\u001b[0m |     \u001b[31m0.8730\u001b[0m |       \u001b[31m0.8730\u001b[0m |  349.0000 | 1.00e-02 |   18.5799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.84it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   43 |         \u001b[32m0.0315\u001b[0m |   \u001b[32m0.9760\u001b[0m | \u001b[31m0.8092\u001b[0m |     \u001b[31m0.8092\u001b[0m |       \u001b[31m0.8092\u001b[0m |  357.0000 | 1.00e-02 |   18.5697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   44 |         \u001b[31m0.0554\u001b[0m |   \u001b[31m0.9348\u001b[0m | \u001b[31m0.8485\u001b[0m |     \u001b[31m0.8485\u001b[0m |       \u001b[31m0.8485\u001b[0m |  370.0000 | 1.00e-02 |   18.6661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   45 |         \u001b[31m0.0604\u001b[0m |   \u001b[31m0.9167\u001b[0m | \u001b[32m0.9134\u001b[0m |     \u001b[32m0.9134\u001b[0m |       \u001b[32m0.9134\u001b[0m |  379.0000 | 1.00e-02 |   18.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46 |         \u001b[31m0.0642\u001b[0m |   \u001b[31m0.9252\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  371.0000 | 1.00e-02 |   18.7906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   47 |         \u001b[31m0.0548\u001b[0m |   \u001b[31m0.9515\u001b[0m | \u001b[31m0.5909\u001b[0m |     \u001b[31m0.5909\u001b[0m |       \u001b[31m0.5909\u001b[0m |  364.0000 | 1.00e-02 |   19.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48 |         \u001b[31m0.0319\u001b[0m |   \u001b[31m0.9622\u001b[0m | \u001b[31m0.8571\u001b[0m |     \u001b[31m0.8571\u001b[0m |       \u001b[31m0.8571\u001b[0m |  370.0000 | 1.00e-02 |   18.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49 |         \u001b[31m0.0490\u001b[0m |   \u001b[31m0.9237\u001b[0m | \u001b[31m0.8682\u001b[0m |     \u001b[31m0.8682\u001b[0m |       \u001b[31m0.8682\u001b[0m |  376.0000 | 1.00e-02 |   19.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50 |         \u001b[31m0.0365\u001b[0m |   \u001b[31m0.9436\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  381.0000 | 1.00e-02 |   18.8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   51 |         \u001b[32m0.0290\u001b[0m |   \u001b[31m0.9699\u001b[0m | \u001b[31m0.6243\u001b[0m |     \u001b[31m0.6243\u001b[0m |       \u001b[31m0.6243\u001b[0m |  384.0000 | 1.00e-02 |   19.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   52 |         \u001b[32m0.0173\u001b[0m |   \u001b[32m0.9825\u001b[0m | \u001b[31m0.8682\u001b[0m |     \u001b[31m0.8682\u001b[0m |       \u001b[31m0.8682\u001b[0m |  371.0000 | 1.00e-02 |   18.7216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 |         \u001b[31m0.0548\u001b[0m |   \u001b[31m0.9545\u001b[0m | \u001b[31m0.8960\u001b[0m |     \u001b[31m0.8960\u001b[0m |       \u001b[31m0.8960\u001b[0m |  373.0000 | 1.00e-02 |   18.6553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.76it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   54 |         \u001b[31m0.0407\u001b[0m |   \u001b[31m0.9570\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  371.0000 | 1.00e-02 |   19.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   55 |         \u001b[31m0.0484\u001b[0m |   \u001b[31m0.9687\u001b[0m | \u001b[31m0.8871\u001b[0m |     \u001b[31m0.8871\u001b[0m |       \u001b[31m0.8871\u001b[0m |  369.0000 | 1.00e-02 |   18.8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.77it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   56 |         \u001b[31m0.0309\u001b[0m |   \u001b[31m0.9733\u001b[0m | \u001b[31m0.8060\u001b[0m |     \u001b[31m0.8060\u001b[0m |       \u001b[31m0.8060\u001b[0m |  377.0000 | 1.00e-02 |   18.9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   57 |         \u001b[31m0.0416\u001b[0m |   \u001b[31m0.9571\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  351.0000 | 1.00e-02 |   18.8804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58 |         \u001b[31m0.0482\u001b[0m |   \u001b[31m0.9412\u001b[0m | \u001b[31m0.8750\u001b[0m |     \u001b[31m0.8750\u001b[0m |       \u001b[31m0.8750\u001b[0m |  356.0000 | 1.00e-02 |   18.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 |         \u001b[31m0.0658\u001b[0m |   \u001b[31m0.9188\u001b[0m | \u001b[31m0.1896\u001b[0m |     \u001b[31m0.1896\u001b[0m |       \u001b[31m0.1896\u001b[0m |  360.0000 | 1.00e-02 |   18.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   60 |         \u001b[31m0.0689\u001b[0m |   \u001b[31m0.8981\u001b[0m | \u001b[31m0.7907\u001b[0m |     \u001b[31m0.7907\u001b[0m |       \u001b[31m0.7907\u001b[0m |  365.0000 | 1.00e-02 |   18.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   61 |         \u001b[31m0.0592\u001b[0m |   \u001b[31m0.8895\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  362.0000 | 1.00e-02 |   18.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.77it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   62 |         \u001b[31m0.0301\u001b[0m |   \u001b[31m0.9628\u001b[0m | \u001b[31m0.8333\u001b[0m |     \u001b[31m0.8333\u001b[0m |       \u001b[31m0.8333\u001b[0m |  362.0000 | 1.00e-02 |   19.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   63 |         \u001b[31m0.0287\u001b[0m |   \u001b[31m0.9562\u001b[0m | \u001b[31m0.8154\u001b[0m |     \u001b[31m0.8154\u001b[0m |       \u001b[31m0.8154\u001b[0m |  391.0000 | 1.00e-02 |   18.8402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.76it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   64 |         \u001b[31m0.0753\u001b[0m |   \u001b[31m0.9272\u001b[0m | \u001b[31m0.8125\u001b[0m |     \u001b[31m0.8125\u001b[0m |       \u001b[31m0.8125\u001b[0m |  353.0000 | 1.00e-02 |   19.0556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   65 |         \u001b[31m0.0434\u001b[0m |   \u001b[31m0.9410\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  357.0000 | 1.00e-02 |   18.7215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   66 |         \u001b[31m0.0209\u001b[0m |   \u001b[31m0.9792\u001b[0m | \u001b[31m0.8571\u001b[0m |     \u001b[31m0.8571\u001b[0m |       \u001b[31m0.8571\u001b[0m |  384.0000 | 1.00e-02 |   18.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   67 |         \u001b[31m0.0533\u001b[0m |   \u001b[31m0.9571\u001b[0m | \u001b[31m0.8871\u001b[0m |     \u001b[31m0.8871\u001b[0m |       \u001b[31m0.8871\u001b[0m |  363.0000 | 1.00e-02 |   18.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   68 |         \u001b[31m0.0236\u001b[0m |   \u001b[31m0.9634\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  357.0000 | 1.00e-02 |   18.9132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.76it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   69 |         \u001b[32m0.0117\u001b[0m |   \u001b[31m0.9773\u001b[0m | \u001b[31m0.8217\u001b[0m |     \u001b[31m0.8217\u001b[0m |       \u001b[31m0.8217\u001b[0m |  353.0000 | 1.00e-02 |   19.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   70 |         \u001b[32m0.0087\u001b[0m |   \u001b[32m0.9946\u001b[0m | \u001b[31m0.8346\u001b[0m |     \u001b[31m0.8346\u001b[0m |       \u001b[31m0.8346\u001b[0m |  371.0000 | 1.00e-02 |   18.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   71 |         \u001b[31m0.0159\u001b[0m |   \u001b[31m0.9777\u001b[0m | \u001b[31m0.8615\u001b[0m |     \u001b[31m0.8615\u001b[0m |       \u001b[31m0.8615\u001b[0m |  360.0000 | 1.00e-02 |   18.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   72 |         \u001b[31m0.0417\u001b[0m |   \u001b[31m0.9895\u001b[0m | \u001b[31m0.8209\u001b[0m |     \u001b[31m0.8209\u001b[0m |       \u001b[31m0.8209\u001b[0m |  381.0000 | 1.00e-02 |   19.0527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   73 |         \u001b[31m0.0594\u001b[0m |   \u001b[31m0.9310\u001b[0m | \u001b[31m0.8504\u001b[0m |     \u001b[31m0.8504\u001b[0m |       \u001b[31m0.8504\u001b[0m |  373.0000 | 1.00e-02 |   18.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   74 |         \u001b[31m0.0414\u001b[0m |   \u001b[31m0.9404\u001b[0m | \u001b[31m0.8500\u001b[0m |     \u001b[31m0.8500\u001b[0m |       \u001b[31m0.8500\u001b[0m |  364.0000 | 1.00e-02 |   18.8012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   75 |         \u001b[31m0.0587\u001b[0m |   \u001b[31m0.9169\u001b[0m | \u001b[31m0.8837\u001b[0m |     \u001b[31m0.8837\u001b[0m |       \u001b[31m0.8837\u001b[0m |  387.0000 | 1.00e-02 |   18.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.77it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   76 |         \u001b[31m0.0166\u001b[0m |   \u001b[31m0.9872\u001b[0m | \u001b[31m0.8462\u001b[0m |     \u001b[31m0.8462\u001b[0m |       \u001b[31m0.8462\u001b[0m |  391.0000 | 1.00e-02 |   19.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.75it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   77 |         \u001b[31m0.0126\u001b[0m |   \u001b[31m0.9872\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  354.0000 | 1.00e-02 |   19.1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.77it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   78 |         \u001b[31m0.0148\u001b[0m |   \u001b[31m0.9762\u001b[0m | \u001b[31m0.8618\u001b[0m |     \u001b[31m0.8618\u001b[0m |       \u001b[31m0.8618\u001b[0m |  378.0000 | 1.00e-02 |   19.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   79 |         \u001b[31m0.0307\u001b[0m |   \u001b[31m0.9545\u001b[0m | \u001b[31m0.8780\u001b[0m |     \u001b[31m0.8780\u001b[0m |       \u001b[31m0.8780\u001b[0m |  373.0000 | 1.00e-02 |   18.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.75it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   80 |         \u001b[31m0.0375\u001b[0m |   \u001b[31m0.9710\u001b[0m | \u001b[31m0.7857\u001b[0m |     \u001b[31m0.7857\u001b[0m |       \u001b[31m0.7857\u001b[0m |  365.0000 | 1.00e-02 |   19.3987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   81 |         \u001b[31m0.0437\u001b[0m |   \u001b[31m0.9571\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  363.0000 | 1.00e-02 |   18.8439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   82 |         \u001b[31m0.0674\u001b[0m |   \u001b[31m0.9418\u001b[0m | \u001b[31m0.8976\u001b[0m |     \u001b[31m0.8976\u001b[0m |       \u001b[31m0.8976\u001b[0m |  395.0000 | 1.00e-02 |   18.8852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83 |         \u001b[31m0.0643\u001b[0m |   \u001b[31m0.9229\u001b[0m | \u001b[31m0.7862\u001b[0m |     \u001b[31m0.7862\u001b[0m |       \u001b[31m0.7862\u001b[0m |  375.0000 | 1.00e-02 |   18.9392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84 |         \u001b[31m0.0551\u001b[0m |   \u001b[31m0.9525\u001b[0m | \u001b[31m0.6853\u001b[0m |     \u001b[31m0.6853\u001b[0m |       \u001b[31m0.6853\u001b[0m |  348.0000 | 1.00e-02 |   18.9536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.76it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   85 |         \u001b[31m0.0188\u001b[0m |   \u001b[31m0.9798\u001b[0m | \u001b[31m0.8547\u001b[0m |     \u001b[31m0.8547\u001b[0m |       \u001b[31m0.8547\u001b[0m |  371.0000 | 1.00e-02 |   19.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   86 |         \u001b[31m0.0471\u001b[0m |   \u001b[31m0.9781\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  368.0000 | 1.00e-02 |   18.8490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   87 |         \u001b[31m0.0344\u001b[0m |   \u001b[31m0.9621\u001b[0m | \u001b[31m0.8640\u001b[0m |     \u001b[31m0.8640\u001b[0m |       \u001b[31m0.8640\u001b[0m |  396.0000 | 1.00e-02 |   18.6690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   88 |         \u001b[31m0.0663\u001b[0m |   \u001b[31m0.9635\u001b[0m | \u001b[31m0.7172\u001b[0m |     \u001b[31m0.7172\u001b[0m |       \u001b[31m0.7172\u001b[0m |  370.0000 | 1.00e-02 |   18.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   89 |         \u001b[31m0.0553\u001b[0m |   \u001b[31m0.9441\u001b[0m | \u001b[31m0.8682\u001b[0m |     \u001b[31m0.8682\u001b[0m |       \u001b[31m0.8682\u001b[0m |  359.0000 | 1.00e-02 |   18.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   90 |         \u001b[31m0.0928\u001b[0m |   \u001b[31m0.8902\u001b[0m | \u001b[31m0.7812\u001b[0m |     \u001b[31m0.7812\u001b[0m |       \u001b[31m0.7812\u001b[0m |  346.0000 | 1.00e-02 |   18.6747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   91 |         \u001b[31m0.0164\u001b[0m |   \u001b[31m0.9702\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  352.0000 | 1.00e-02 |   18.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   92 |         \u001b[31m0.0234\u001b[0m |   \u001b[31m0.9858\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  387.0000 | 1.00e-02 |   18.6910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   93 |         \u001b[31m0.0111\u001b[0m |   \u001b[31m0.9852\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  374.0000 | 1.00e-02 |   18.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   94 |         \u001b[32m0.0051\u001b[0m |   \u001b[32m0.9957\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  351.0000 | 1.00e-02 |   18.7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   95 |         \u001b[32m0.0047\u001b[0m |   \u001b[31m0.9918\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  363.0000 | 1.00e-02 |   18.6105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   96 |         \u001b[31m0.0064\u001b[0m |   \u001b[31m0.9892\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  370.0000 | 1.00e-02 |   18.7354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   97 |         \u001b[31m0.0285\u001b[0m |   \u001b[31m0.9842\u001b[0m | \u001b[31m0.8640\u001b[0m |     \u001b[31m0.8640\u001b[0m |       \u001b[31m0.8640\u001b[0m |  378.0000 | 1.00e-02 |   18.8558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.77it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   98 |         \u001b[31m0.1022\u001b[0m |   \u001b[31m0.9266\u001b[0m | \u001b[31m0.8926\u001b[0m |     \u001b[31m0.8926\u001b[0m |       \u001b[31m0.8926\u001b[0m |  377.0000 | 1.00e-02 |   18.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.77it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   99 |         \u001b[31m0.0810\u001b[0m |   \u001b[31m0.9514\u001b[0m | \u001b[31m0.8837\u001b[0m |     \u001b[31m0.8837\u001b[0m |       \u001b[31m0.8837\u001b[0m |  351.0000 | 1.00e-02 |   18.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100 |         \u001b[31m0.0301\u001b[0m |   \u001b[31m0.9621\u001b[0m | \u001b[31m0.8661\u001b[0m |     \u001b[31m0.8661\u001b[0m |       \u001b[31m0.8661\u001b[0m |  397.0000 | 1.00e-02 |   18.9663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  101 |         \u001b[31m0.0174\u001b[0m |   \u001b[31m0.9604\u001b[0m | \u001b[31m0.8397\u001b[0m |     \u001b[31m0.8397\u001b[0m |       \u001b[31m0.8397\u001b[0m |  392.0000 | 1.00e-02 |   18.7711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102 |         \u001b[31m0.0098\u001b[0m |   \u001b[31m0.9906\u001b[0m | \u001b[31m0.8800\u001b[0m |     \u001b[31m0.8800\u001b[0m |       \u001b[31m0.8800\u001b[0m |  373.0000 | 1.00e-02 |   18.6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  103 |         \u001b[31m0.0124\u001b[0m |   \u001b[31m0.9879\u001b[0m | \u001b[31m0.8504\u001b[0m |     \u001b[31m0.8504\u001b[0m |       \u001b[31m0.8504\u001b[0m |  373.0000 | 1.00e-02 |   18.7732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  104 |         \u001b[31m0.0105\u001b[0m |   \u001b[31m0.9861\u001b[0m | \u001b[31m0.8730\u001b[0m |     \u001b[31m0.8730\u001b[0m |       \u001b[31m0.8730\u001b[0m |  360.0000 | 1.00e-02 |   18.5930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  105 |         \u001b[31m0.0458\u001b[0m |   \u001b[31m0.9896\u001b[0m | \u001b[31m0.7051\u001b[0m |     \u001b[31m0.7051\u001b[0m |       \u001b[31m0.7051\u001b[0m |  384.0000 | 1.00e-02 |   19.1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  106 |         \u001b[31m0.0170\u001b[0m |   \u001b[31m0.9815\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  379.0000 | 1.00e-02 |   18.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  107 |         \u001b[31m0.0531\u001b[0m |   \u001b[31m0.9608\u001b[0m | \u001b[31m0.7846\u001b[0m |     \u001b[31m0.7846\u001b[0m |       \u001b[31m0.7846\u001b[0m |  369.0000 | 1.00e-02 |   18.8167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  108 |         \u001b[31m0.0557\u001b[0m |   \u001b[31m0.9456\u001b[0m | \u001b[31m0.8397\u001b[0m |     \u001b[31m0.8397\u001b[0m |       \u001b[31m0.8397\u001b[0m |  359.0000 | 1.00e-02 |   18.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  109 |         \u001b[31m0.0301\u001b[0m |   \u001b[31m0.9763\u001b[0m | \u001b[31m0.8750\u001b[0m |     \u001b[31m0.8750\u001b[0m |       \u001b[31m0.8750\u001b[0m |  381.0000 | 1.00e-02 |   18.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.84it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  110 |         \u001b[31m0.0499\u001b[0m |   \u001b[31m0.9328\u001b[0m | \u001b[31m0.8244\u001b[0m |     \u001b[31m0.8244\u001b[0m |       \u001b[31m0.8244\u001b[0m |  368.0000 | 1.00e-02 |   18.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  111 |         \u001b[31m0.0291\u001b[0m |   \u001b[31m0.9749\u001b[0m | \u001b[31m0.8852\u001b[0m |     \u001b[31m0.8852\u001b[0m |       \u001b[31m0.8852\u001b[0m |  398.0000 | 1.00e-02 |   18.4145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  112 |         \u001b[31m0.0237\u001b[0m |   \u001b[31m0.9761\u001b[0m | \u001b[31m0.8750\u001b[0m |     \u001b[31m0.8750\u001b[0m |       \u001b[31m0.8750\u001b[0m |  356.0000 | 1.00e-02 |   18.4058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  113 |         \u001b[31m0.0619\u001b[0m |   \u001b[31m0.9511\u001b[0m | \u001b[31m0.8780\u001b[0m |     \u001b[31m0.8780\u001b[0m |       \u001b[31m0.8780\u001b[0m |  370.0000 | 1.00e-02 |   18.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  114 |         \u001b[31m0.0089\u001b[0m |   \u001b[31m0.9872\u001b[0m | \u001b[31m0.8960\u001b[0m |     \u001b[31m0.8960\u001b[0m |       \u001b[31m0.8960\u001b[0m |  390.0000 | 1.00e-02 |   18.7530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:08,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  115 |         \u001b[31m0.0137\u001b[0m |   \u001b[31m0.9841\u001b[0m | \u001b[31m0.8889\u001b[0m |     \u001b[31m0.8889\u001b[0m |       \u001b[31m0.8889\u001b[0m |  378.0000 | 1.00e-02 |   18.9560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  116 |         \u001b[31m0.0209\u001b[0m |   \u001b[31m0.9774\u001b[0m | \u001b[31m0.8710\u001b[0m |     \u001b[31m0.8710\u001b[0m |       \u001b[31m0.8710\u001b[0m |  376.0000 | 1.00e-02 |   18.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  117 |         \u001b[31m0.0115\u001b[0m |   \u001b[31m0.9759\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  354.0000 | 1.00e-02 |   18.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  118 |         \u001b[31m0.0087\u001b[0m |   \u001b[31m0.9918\u001b[0m | \u001b[31m0.8800\u001b[0m |     \u001b[31m0.8800\u001b[0m |       \u001b[31m0.8800\u001b[0m |  364.0000 | 1.00e-02 |   18.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.79it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  119 |         \u001b[31m0.0262\u001b[0m |   \u001b[31m0.9906\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  371.0000 | 1.00e-02 |   18.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.78it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  120 |         \u001b[31m0.0286\u001b[0m |   \u001b[31m0.9592\u001b[0m | \u001b[31m0.8438\u001b[0m |     \u001b[31m0.8438\u001b[0m |       \u001b[31m0.8438\u001b[0m |  355.0000 | 1.00e-02 |   19.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  121 |         \u001b[31m0.0418\u001b[0m |   \u001b[31m0.9497\u001b[0m | \u001b[31m0.8750\u001b[0m |     \u001b[31m0.8750\u001b[0m |       \u001b[31m0.8750\u001b[0m |  356.0000 | 1.00e-02 |   18.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  122 |         \u001b[31m0.0284\u001b[0m |   \u001b[31m0.9668\u001b[0m | \u001b[32m0.9180\u001b[0m |     \u001b[32m0.9180\u001b[0m |       \u001b[32m0.9180\u001b[0m |  346.0000 | 1.00e-02 |   18.6728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  123 |         \u001b[31m0.0671\u001b[0m |   \u001b[31m0.9533\u001b[0m | \u001b[31m0.8271\u001b[0m |     \u001b[31m0.8271\u001b[0m |       \u001b[31m0.8271\u001b[0m |  353.0000 | 1.00e-02 |   18.5872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  124 |         \u001b[31m0.0507\u001b[0m |   \u001b[31m0.9565\u001b[0m | \u001b[31m0.8889\u001b[0m |     \u001b[31m0.8889\u001b[0m |       \u001b[31m0.8889\u001b[0m |  390.0000 | 1.00e-02 |   18.4440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.76it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  125 |         \u001b[31m0.1187\u001b[0m |   \u001b[31m0.9301\u001b[0m | \u001b[31m0.8682\u001b[0m |     \u001b[31m0.8682\u001b[0m |       \u001b[31m0.8682\u001b[0m |  358.0000 | 1.00e-02 |   19.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  126 |         \u001b[31m0.0106\u001b[0m |   \u001b[31m0.9720\u001b[0m | \u001b[31m0.8889\u001b[0m |     \u001b[31m0.8889\u001b[0m |       \u001b[31m0.8889\u001b[0m |  376.0000 | 1.00e-02 |   18.8803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.93it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  127 |         \u001b[31m0.0251\u001b[0m |   \u001b[31m0.9698\u001b[0m | \u001b[31m0.8682\u001b[0m |     \u001b[31m0.8682\u001b[0m |       \u001b[31m0.8682\u001b[0m |  349.0000 | 1.00e-02 |   18.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.97it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  128 |         \u001b[31m0.0490\u001b[0m |   \u001b[31m0.9679\u001b[0m | \u001b[31m0.8548\u001b[0m |     \u001b[31m0.8548\u001b[0m |       \u001b[31m0.8548\u001b[0m |  358.0000 | 1.00e-02 |   17.7736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  129 |         \u001b[31m0.0490\u001b[0m |   \u001b[31m0.9472\u001b[0m | \u001b[31m0.8852\u001b[0m |     \u001b[31m0.8852\u001b[0m |       \u001b[31m0.8852\u001b[0m |  379.0000 | 1.00e-02 |   18.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  130 |         \u001b[31m0.0329\u001b[0m |   \u001b[31m0.9739\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  366.0000 | 1.00e-02 |   18.7205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  131 |         \u001b[31m0.0368\u001b[0m |   \u001b[31m0.9808\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  367.0000 | 1.00e-02 |   18.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.84it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  132 |         \u001b[31m0.0154\u001b[0m |   \u001b[31m0.9821\u001b[0m | \u001b[31m0.8346\u001b[0m |     \u001b[31m0.8346\u001b[0m |       \u001b[31m0.8346\u001b[0m |  364.0000 | 1.00e-02 |   18.5588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  133 |         \u001b[31m0.0404\u001b[0m |   \u001b[31m0.9782\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  343.0000 | 1.00e-02 |   18.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.95it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  134 |         \u001b[31m0.0780\u001b[0m |   \u001b[31m0.9526\u001b[0m | \u001b[31m0.8837\u001b[0m |     \u001b[31m0.8837\u001b[0m |       \u001b[31m0.8837\u001b[0m |  375.0000 | 1.00e-02 |   17.9138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.92it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  135 |         \u001b[31m0.0728\u001b[0m |   \u001b[31m0.9487\u001b[0m | \u001b[31m0.8029\u001b[0m |     \u001b[31m0.8029\u001b[0m |       \u001b[31m0.8029\u001b[0m |  361.0000 | 1.00e-02 |   18.2606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  136 |         \u001b[31m0.0258\u001b[0m |   \u001b[31m0.9803\u001b[0m | \u001b[31m0.8640\u001b[0m |     \u001b[31m0.8640\u001b[0m |       \u001b[31m0.8640\u001b[0m |  357.0000 | 1.00e-02 |   18.4257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  137 |         \u001b[31m0.0288\u001b[0m |   \u001b[31m0.9589\u001b[0m | \u001b[31m0.8871\u001b[0m |     \u001b[31m0.8871\u001b[0m |       \u001b[31m0.8871\u001b[0m |  368.0000 | 1.00e-02 |   18.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  138 |         \u001b[31m0.0146\u001b[0m |   \u001b[31m0.9736\u001b[0m | \u001b[31m0.8750\u001b[0m |     \u001b[31m0.8750\u001b[0m |       \u001b[31m0.8750\u001b[0m |  361.0000 | 1.00e-02 |   18.3936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  139 |         \u001b[31m0.0222\u001b[0m |   \u001b[31m0.9889\u001b[0m | \u001b[31m0.9048\u001b[0m |     \u001b[31m0.9048\u001b[0m |       \u001b[31m0.9048\u001b[0m |  360.0000 | 1.00e-02 |   18.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.90it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  140 |         \u001b[31m0.0418\u001b[0m |   \u001b[31m0.9775\u001b[0m | \u001b[31m0.8462\u001b[0m |     \u001b[31m0.8462\u001b[0m |       \u001b[31m0.8462\u001b[0m |  381.0000 | 1.00e-02 |   18.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  141 |         \u001b[31m0.1261\u001b[0m |   \u001b[31m0.8988\u001b[0m | \u001b[31m0.8235\u001b[0m |     \u001b[31m0.8235\u001b[0m |       \u001b[31m0.8235\u001b[0m |  378.0000 | 1.00e-02 |   18.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  142 |         \u001b[31m0.0406\u001b[0m |   \u001b[31m0.9615\u001b[0m | \u001b[31m0.9120\u001b[0m |     \u001b[31m0.9120\u001b[0m |       \u001b[31m0.9120\u001b[0m |  365.0000 | 1.00e-02 |   18.5984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  143 |         \u001b[31m0.0123\u001b[0m |   \u001b[31m0.9810\u001b[0m | \u001b[31m0.8000\u001b[0m |     \u001b[31m0.8000\u001b[0m |       \u001b[31m0.8000\u001b[0m |  369.0000 | 1.00e-02 |   18.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  144 |         \u001b[31m0.0099\u001b[0m |   \u001b[31m0.9823\u001b[0m | \u001b[31m0.9062\u001b[0m |     \u001b[31m0.9062\u001b[0m |       \u001b[31m0.9062\u001b[0m |  340.0000 | 1.00e-02 |   18.6661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.89it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  145 |         \u001b[31m0.0262\u001b[0m |   \u001b[31m0.9811\u001b[0m | \u001b[32m0.9206\u001b[0m |     \u001b[32m0.9206\u001b[0m |       \u001b[32m0.9206\u001b[0m |  343.0000 | 1.00e-02 |   18.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.96it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:09,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  146 |         \u001b[31m0.0095\u001b[0m |   \u001b[31m0.9821\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  391.0000 | 1.00e-02 |   17.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:08,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  147 |         \u001b[31m0.0172\u001b[0m |   \u001b[31m0.9806\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  360.0000 | 1.00e-02 |   18.3478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.90it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  148 |         \u001b[31m0.1315\u001b[0m |   \u001b[31m0.9081\u001b[0m | \u001b[31m0.8906\u001b[0m |     \u001b[31m0.8906\u001b[0m |       \u001b[31m0.8906\u001b[0m |  363.0000 | 1.00e-02 |   18.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  149 |         \u001b[31m0.0381\u001b[0m |   \u001b[31m0.9615\u001b[0m | \u001b[31m0.3684\u001b[0m |     \u001b[31m0.3684\u001b[0m |       \u001b[31m0.3684\u001b[0m |  339.0000 | 1.00e-02 |   19.8607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:09,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  150 |         \u001b[31m0.4968\u001b[0m |   \u001b[31m0.8431\u001b[0m | \u001b[31m0.8092\u001b[0m |     \u001b[31m0.8092\u001b[0m |       \u001b[31m0.8092\u001b[0m |  358.0000 | 1.00e-02 |   18.7966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  151 |         \u001b[31m0.0814\u001b[0m |   \u001b[31m0.8991\u001b[0m | \u001b[31m0.8480\u001b[0m |     \u001b[31m0.8480\u001b[0m |       \u001b[31m0.8480\u001b[0m |  370.0000 | 1.00e-02 |   18.4824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.90it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  152 |         \u001b[31m0.0647\u001b[0m |   \u001b[31m0.9664\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  375.0000 | 1.00e-02 |   18.2172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  153 |         \u001b[31m0.0236\u001b[0m |   \u001b[31m0.9568\u001b[0m | \u001b[31m0.8387\u001b[0m |     \u001b[31m0.8387\u001b[0m |       \u001b[31m0.8387\u001b[0m |  360.0000 | 1.00e-02 |   18.5158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  154 |         \u001b[31m0.0175\u001b[0m |   \u001b[31m0.9809\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  366.0000 | 1.00e-02 |   18.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.80it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  155 |         \u001b[31m0.0108\u001b[0m |   \u001b[31m0.9841\u001b[0m | \u001b[31m0.8837\u001b[0m |     \u001b[31m0.8837\u001b[0m |       \u001b[31m0.8837\u001b[0m |  377.0000 | 1.00e-02 |   19.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  156 |         \u001b[32m0.0025\u001b[0m |   \u001b[31m0.9946\u001b[0m | \u001b[31m0.8837\u001b[0m |     \u001b[31m0.8837\u001b[0m |       \u001b[31m0.8837\u001b[0m |  373.0000 | 1.00e-02 |   18.3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.89it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:07,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  157 |         \u001b[31m0.0611\u001b[0m |   \u001b[31m0.9421\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  360.0000 | 1.00e-02 |   18.2479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.90it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  158 |         \u001b[31m0.0289\u001b[0m |   \u001b[31m0.9723\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  381.0000 | 1.00e-02 |   18.2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.92it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  159 |         \u001b[31m0.0198\u001b[0m |   \u001b[31m0.9897\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  340.0000 | 1.00e-02 |   18.1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.76it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  160 |         \u001b[31m0.0359\u001b[0m |   \u001b[31m0.9665\u001b[0m | \u001b[31m0.8504\u001b[0m |     \u001b[31m0.8504\u001b[0m |       \u001b[31m0.8504\u001b[0m |  371.0000 | 1.00e-02 |   19.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161 |         \u001b[31m0.0488\u001b[0m |   \u001b[31m0.9602\u001b[0m | \u001b[31m0.8217\u001b[0m |     \u001b[31m0.8217\u001b[0m |       \u001b[31m0.8217\u001b[0m |  375.0000 | 1.00e-02 |   18.7145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  3.02it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  162 |         \u001b[31m0.0708\u001b[0m |   \u001b[31m0.9508\u001b[0m | \u001b[31m0.8661\u001b[0m |     \u001b[31m0.8661\u001b[0m |       \u001b[31m0.8661\u001b[0m |  362.0000 | 1.00e-02 |   17.6178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  3.05it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  163 |         \u001b[31m0.0302\u001b[0m |   \u001b[31m0.9730\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  354.0000 | 1.00e-02 |   17.4307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.93it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  164 |         \u001b[31m0.0291\u001b[0m |   \u001b[31m0.9867\u001b[0m | \u001b[31m0.8943\u001b[0m |     \u001b[31m0.8943\u001b[0m |       \u001b[31m0.8943\u001b[0m |  376.0000 | 1.00e-02 |   18.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.82it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  165 |         \u001b[31m0.0332\u001b[0m |   \u001b[31m0.9719\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  374.0000 | 1.00e-02 |   18.7871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.93it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  166 |         \u001b[31m0.0232\u001b[0m |   \u001b[31m0.9720\u001b[0m | \u001b[31m0.8594\u001b[0m |     \u001b[31m0.8594\u001b[0m |       \u001b[31m0.8594\u001b[0m |  376.0000 | 1.00e-02 |   18.1232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  3.04it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  167 |         \u001b[31m0.0437\u001b[0m |   \u001b[31m0.9711\u001b[0m | \u001b[31m0.8682\u001b[0m |     \u001b[31m0.8682\u001b[0m |       \u001b[31m0.8682\u001b[0m |  362.0000 | 1.00e-02 |   17.4406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.98it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  168 |         \u001b[31m0.0292\u001b[0m |   \u001b[31m0.9790\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  358.0000 | 1.00e-02 |   17.7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  3.00it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  169 |         \u001b[31m0.5766\u001b[0m |   \u001b[31m0.8976\u001b[0m | \u001b[31m0.8871\u001b[0m |     \u001b[31m0.8871\u001b[0m |       \u001b[31m0.8871\u001b[0m |  368.0000 | 1.00e-02 |   17.5910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.95it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  170 |         \u001b[31m0.0230\u001b[0m |   \u001b[31m0.9803\u001b[0m | \u001b[31m0.8682\u001b[0m |     \u001b[31m0.8682\u001b[0m |       \u001b[31m0.8682\u001b[0m |  379.0000 | 1.00e-02 |   17.8412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.94it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  171 |         \u001b[31m0.0430\u001b[0m |   \u001b[31m0.9770\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  369.0000 | 1.00e-02 |   18.1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  172 |         \u001b[31m0.0200\u001b[0m |   \u001b[31m0.9689\u001b[0m | \u001b[31m0.8615\u001b[0m |     \u001b[31m0.8615\u001b[0m |       \u001b[31m0.8615\u001b[0m |  385.0000 | 1.00e-02 |   18.5785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.90it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  173 |         \u001b[31m0.0563\u001b[0m |   \u001b[31m0.9730\u001b[0m | \u001b[31m0.8085\u001b[0m |     \u001b[31m0.8085\u001b[0m |       \u001b[31m0.8085\u001b[0m |  351.0000 | 1.00e-02 |   18.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.92it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:08,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  174 |         \u001b[31m0.0794\u001b[0m |   \u001b[31m0.9618\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  379.0000 | 1.00e-02 |   18.1207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.88it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  175 |         \u001b[31m0.1035\u001b[0m |   \u001b[31m0.9243\u001b[0m | \u001b[31m0.8281\u001b[0m |     \u001b[31m0.8281\u001b[0m |       \u001b[31m0.8281\u001b[0m |  368.0000 | 1.00e-02 |   18.3669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  176 |         \u001b[31m0.0255\u001b[0m |   \u001b[31m0.9719\u001b[0m | \u001b[31m0.9062\u001b[0m |     \u001b[31m0.9062\u001b[0m |       \u001b[31m0.9062\u001b[0m |  372.0000 | 1.00e-02 |   18.3059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  177 |         \u001b[31m0.0341\u001b[0m |   \u001b[31m0.9927\u001b[0m | \u001b[31m0.9134\u001b[0m |     \u001b[31m0.9134\u001b[0m |       \u001b[31m0.9134\u001b[0m |  342.0000 | 1.00e-02 |   18.7758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  178 |         \u001b[31m0.0191\u001b[0m |   \u001b[31m0.9868\u001b[0m | \u001b[31m0.8730\u001b[0m |     \u001b[31m0.8730\u001b[0m |       \u001b[31m0.8730\u001b[0m |  380.0000 | 1.00e-02 |   18.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.84it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  179 |         \u001b[31m0.0110\u001b[0m |   \u001b[31m0.9824\u001b[0m | \u001b[31m0.9062\u001b[0m |     \u001b[31m0.9062\u001b[0m |       \u001b[31m0.9062\u001b[0m |  398.0000 | 1.00e-02 |   18.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.83it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  180 |         \u001b[32m0.0016\u001b[0m |   \u001b[32m0.9959\u001b[0m | \u001b[31m0.8769\u001b[0m |     \u001b[31m0.8769\u001b[0m |       \u001b[31m0.8769\u001b[0m |  369.0000 | 1.00e-02 |   18.6444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.81it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  181 |         \u001b[31m0.0054\u001b[0m |   \u001b[31m0.9933\u001b[0m | \u001b[31m0.8837\u001b[0m |     \u001b[31m0.8837\u001b[0m |       \u001b[31m0.8837\u001b[0m |  377.0000 | 1.00e-02 |   18.7163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.84it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  182 |         \u001b[31m0.0321\u001b[0m |   \u001b[31m0.9848\u001b[0m | \u001b[31m0.8702\u001b[0m |     \u001b[31m0.8702\u001b[0m |       \u001b[31m0.8702\u001b[0m |  363.0000 | 1.00e-02 |   18.5767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  183 |         \u001b[31m0.0315\u001b[0m |   \u001b[31m0.9638\u001b[0m | \u001b[31m0.8819\u001b[0m |     \u001b[31m0.8819\u001b[0m |       \u001b[31m0.8819\u001b[0m |  360.0000 | 1.00e-02 |   18.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.92it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  184 |         \u001b[31m0.0079\u001b[0m |   \u001b[31m0.9907\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  377.0000 | 1.00e-02 |   18.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.85it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  185 |         \u001b[31m0.0692\u001b[0m |   \u001b[31m0.9680\u001b[0m | \u001b[31m0.6788\u001b[0m |     \u001b[31m0.6788\u001b[0m |       \u001b[31m0.6788\u001b[0m |  368.0000 | 1.00e-02 |   19.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.88it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  186 |         \u001b[31m0.0526\u001b[0m |   \u001b[31m0.9513\u001b[0m | \u001b[31m0.8244\u001b[0m |     \u001b[31m0.8244\u001b[0m |       \u001b[31m0.8244\u001b[0m |  360.0000 | 1.00e-02 |   18.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.86it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:08,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  187 |         \u001b[31m0.0150\u001b[0m |   \u001b[31m0.9733\u001b[0m | \u001b[31m0.7857\u001b[0m |     \u001b[31m0.7857\u001b[0m |       \u001b[31m0.7857\u001b[0m |  374.0000 | 1.00e-02 |   18.6146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.92it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  188 |         \u001b[31m0.0141\u001b[0m |   \u001b[31m0.9849\u001b[0m | \u001b[31m0.8175\u001b[0m |     \u001b[31m0.8175\u001b[0m |       \u001b[31m0.8175\u001b[0m |  365.0000 | 1.00e-02 |   18.2992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.88it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  189 |         \u001b[31m0.0049\u001b[0m |   \u001b[31m0.9933\u001b[0m | \u001b[31m0.8889\u001b[0m |     \u001b[31m0.8889\u001b[0m |       \u001b[31m0.8889\u001b[0m |  370.0000 | 1.00e-02 |   18.3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.88it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  190 |         \u001b[31m0.0110\u001b[0m |   \u001b[32m0.9961\u001b[0m | \u001b[31m0.8550\u001b[0m |     \u001b[31m0.8550\u001b[0m |       \u001b[31m0.8550\u001b[0m |  387.0000 | 1.00e-02 |   18.3767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.91it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  191 |         \u001b[31m0.0428\u001b[0m |   \u001b[31m0.9907\u001b[0m | \u001b[31m0.8750\u001b[0m |     \u001b[31m0.8750\u001b[0m |       \u001b[31m0.8750\u001b[0m |  378.0000 | 1.00e-02 |   18.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  192 |         \u001b[31m0.1932\u001b[0m |   \u001b[31m0.8963\u001b[0m | \u001b[31m0.3895\u001b[0m |     \u001b[31m0.3895\u001b[0m |       \u001b[31m0.3895\u001b[0m |  365.0000 | 1.00e-02 |   18.5212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.89it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  193 |         \u001b[31m0.0439\u001b[0m |   \u001b[31m0.9475\u001b[0m | \u001b[31m0.7383\u001b[0m |     \u001b[31m0.7383\u001b[0m |       \u001b[31m0.7383\u001b[0m |  364.0000 | 1.00e-02 |   18.3977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.92it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  194 |         \u001b[31m0.0585\u001b[0m |   \u001b[31m0.9613\u001b[0m | \u001b[31m0.8640\u001b[0m |     \u001b[31m0.8640\u001b[0m |       \u001b[31m0.8640\u001b[0m |  346.0000 | 1.00e-02 |   18.2029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.90it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  195 |         \u001b[31m0.0602\u001b[0m |   \u001b[31m0.9653\u001b[0m | \u001b[31m0.8548\u001b[0m |     \u001b[31m0.8548\u001b[0m |       \u001b[31m0.8548\u001b[0m |  375.0000 | 1.00e-02 |   18.1970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.93it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  196 |         \u001b[31m0.0472\u001b[0m |   \u001b[31m0.9677\u001b[0m | \u001b[31m0.8504\u001b[0m |     \u001b[31m0.8504\u001b[0m |       \u001b[31m0.8504\u001b[0m |  357.0000 | 1.00e-02 |   18.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.88it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  197 |         \u001b[31m0.0054\u001b[0m |   \u001b[31m0.9847\u001b[0m | \u001b[31m0.9062\u001b[0m |     \u001b[31m0.9062\u001b[0m |       \u001b[31m0.9062\u001b[0m |  359.0000 | 1.00e-02 |   18.3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:17<00:00,  2.87it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  198 |         \u001b[31m0.0603\u001b[0m |   \u001b[31m0.9619\u001b[0m | \u001b[31m0.8527\u001b[0m |     \u001b[31m0.8527\u001b[0m |       \u001b[31m0.8527\u001b[0m |  341.0000 | 1.00e-02 |   18.4697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  2.95it/s]\n",
      "  2%|▏         | 1/49 [00:00<00:08,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  199 |         \u001b[31m0.0451\u001b[0m |   \u001b[31m0.9649\u001b[0m | \u001b[31m0.9032\u001b[0m |     \u001b[31m0.9032\u001b[0m |       \u001b[31m0.9032\u001b[0m |  354.0000 | 1.00e-02 |   17.8189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:16<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200 |         \u001b[31m0.0273\u001b[0m |   \u001b[31m0.9748\u001b[0m | \u001b[31m0.8682\u001b[0m |     \u001b[31m0.8682\u001b[0m |       \u001b[31m0.8682\u001b[0m |  377.0000 | 1.00e-02 |   17.4596\n",
      "Loading /home/tannier/data/cache/daloux/2bb9f55995f7f9f3/checkpoint-145.pt... Done\n",
      "Model restored to its best self.state: 145\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "from tqdm import tqdm\n",
    "\n",
    "from custom_bert import CustomBertModel\n",
    "from transformers import AdamW, BertModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from logic_crf import CRF, ConstraintFactor, HintFactor, Indexer\n",
    "\n",
    "from nlstruct.environment import get_cache\n",
    "from nlstruct.utils import evaluating, torch_global as tg, freeze\n",
    "from nlstruct.scoring import compute_metrics, merge_pred_and_gold\n",
    "from nlstruct.train import make_optimizer_and_schedules, run_optimization, seed_all\n",
    "from nlstruct.train.schedule import ScaleOnPlateauSchedule, LinearSchedule, ConstantSchedule\n",
    "    \n",
    "device = torch.device('cuda:1')\n",
    "tg.set_device(device)\n",
    "all_preds = []\n",
    "histories = []\n",
    "\n",
    "# To release gpu memory before allocating new parameters for a new model\n",
    "# A better idea would be to run xp in a function, so that all variables are released when exiting the fn\n",
    "# but this way we can debug after this cell if something goes wrong\n",
    "if \"all_nets\" in globals(): del all_nets\n",
    "if \"optim\" in globals(): del optim, \n",
    "if \"schedules\" in globals(): del schedules\n",
    "if \"final_schedule\" in globals(): del final_schedule\n",
    "if \"state\" in globals(): del state\n",
    "    \n",
    "# Hyperparameter search\n",
    "for layer, hidden_dim, scheme, seed, lr, bert_lr, n_schedules, dropout in [\n",
    "    (3, 1024 if \"large\" in bert_name else 768, \"bioul\", 12,  1e-2, 4e-5, 1, 0.1),\n",
    "]:\n",
    "    print(layer, hidden_dim, scheme, seed, lr, bert_lr, n_schedules, dropout)\n",
    "    #seed = 123456\n",
    "    seed_all(seed) # /!\\ Super important to enable reproducibility\n",
    "\n",
    "    tag_dim = 1024 if \"large\" in bert_name else 768#768\n",
    "    max_grad_norm = 5.\n",
    "    #lr = 1e-3\n",
    "    #bert_lr = 6e-5\n",
    "    tags_lr = bert_lr\n",
    "    bert_weight_decay = 0.0000\n",
    "    batch_size = 128\n",
    "    random_perm=True\n",
    "    observed_zone_sizes=None\n",
    "    n_per_zone = \"uniform\"\n",
    "    n_freeze = layer + 2 #4\n",
    "    custom_embeds_layer_index = 19 if \"large\" in bert_name else 11  #layer#2\n",
    "    #hidden_dim = 256\n",
    "    bert_dropout = 0.1\n",
    "    top_dropout = dropout\n",
    "\n",
    "    ner_net = NERNet(\n",
    "            n_tokens=len(vocs[\"token\"]),\n",
    "            token_dim=1024 if \"large\" in bert_name else 768,#768,\n",
    "            n_labels=len(vocs[\"ner_label\"]),\n",
    "            embeddings=CustomBertModel.from_pretrained(bert_name, custom_embeds_layer_index=custom_embeds_layer_index),\n",
    "\n",
    "            dropout=top_dropout,\n",
    "            hidden_dim=hidden_dim,\n",
    "            tag_scheme=scheme,\n",
    "            metric='linear') # cosine might be better but looks less stable, oddly,\n",
    "    all_nets = torch.nn.ModuleDict({\n",
    "        \"ner_net\": ner_net,\n",
    "        \"tag_embeddings\": torch.nn.Embedding(ner_net.crf.num_tags - 1, tag_dim),\n",
    "    }).to(device=tg.device)\n",
    "    del ner_net\n",
    "\n",
    "    for module in all_nets[\"ner_net\"].embeddings.modules():\n",
    "        if isinstance(module, torch.nn.Dropout):\n",
    "            module.p = bert_dropout\n",
    "    all_nets.train()\n",
    "\n",
    "    # Define the optimizer, maybe multiple learning rate / schedules per parameters groups\n",
    "    optim, schedules = make_optimizer_and_schedules(all_nets, AdamW, {\n",
    "        \"lr\": [\n",
    "                               (lr,    bert_lr,    bert_lr,    tags_lr),\n",
    "            (ConstantSchedule, (lr,    bert_lr,    bert_lr,    tags_lr),    15),\n",
    "            (ConstantSchedule, (lr/4,  bert_lr/4,  bert_lr/4,  tags_lr/4),  15),\n",
    "            (ConstantSchedule, (lr/16, bert_lr/16, bert_lr/16, tags_lr/16), 10),\n",
    "            (ConstantSchedule, (lr/64, bert_lr/64, bert_lr/64, tags_lr/64), 10),\n",
    "        ][:n_schedules+1],\n",
    "    }, [\n",
    "        \"(?!ner_net\\.embeddings\\.|tag_embeddings\\.).*\",\n",
    "        \"ner_net\\.embeddings\\..*(bias|LayerNorm\\.weight)\",\n",
    "        \"ner_net\\.embeddings\\..*(?!bias|LayerNorm\\.weight)\",\n",
    "        \"tag_embeddings\\..*\",\n",
    "    ], num_iter_per_epoch=(len(train_batcher) + 1) / batch_size)\n",
    "    final_schedule = ScaleOnPlateauSchedule('lr', optim, patience=4, factor=0.25, verbose=True, mode='max')\n",
    "\n",
    "    # Freeze some bert layers \n",
    "    # - n_freeze = 0 to freeze nothing\n",
    "    # - n_freeze = 1 to freeze word embeddings / position embeddings / ...\n",
    "    # - n_freeze = 2..13 to freeze the first, second ... 12th layer of bert\n",
    "    for name, param in all_nets.named_parameters():\n",
    "        match = re.search(\"\\.(\\d+)\\.\", name)\n",
    "        if match and int(match.group(1)) < n_freeze - 1:\n",
    "            freeze([param])\n",
    "    if n_freeze > 0:\n",
    "        if hasattr(all_nets['ner_net'].embeddings, 'embeddings'):\n",
    "            freeze(all_nets['ner_net'].embeddings.embeddings)\n",
    "        else:\n",
    "            freeze(all_nets['ner_net'].embeddings)\n",
    "\n",
    "    with_tqdm = True\n",
    "    state = {\"all_nets\": all_nets, \"optim\": optim, \"schedules\": schedules, \"final_schedule\": final_schedule}  # all we need to restart the training from a given epoch\n",
    "\n",
    "    def run_epoch():\n",
    "        pred_batches = []\n",
    "        gold_batches = []\n",
    "\n",
    "        total_train_ner_loss = 0\n",
    "        total_train_acc = 0\n",
    "        total_train_ner_size = 0\n",
    "\n",
    "        n_mentions = len(train_batcher[\"mention\"])\n",
    "        n_matched_mentions = 0\n",
    "        n_target_mentions = 0\n",
    "        n_observed_mentions = 0\n",
    "\n",
    "        with tqdm(train_batcher['sentence'].dataloader(batch_size=batch_size, shuffle=True, sparse_sort_on=\"token_mask\", device=device), disable=not with_tqdm) as bar:\n",
    "            for batch_i, batch in enumerate(bar):\n",
    "                optim.zero_grad()\n",
    "\n",
    "                # Shuffle and split mentions in each zone between observed and target\n",
    "                target_mentions, observed_mentions, zone_target_mentions, target_mask = split_zone_mentions(\n",
    "                    batch,\n",
    "                    random_perm=random_perm,\n",
    "                    observed_zone_sizes=observed_zone_sizes,\n",
    "                )\n",
    "                n_target_mentions += len(target_mentions)\n",
    "                n_observed_mentions += len(observed_mentions)\n",
    "\n",
    "                # Compute the tokens label tag embeddings of the observed (maybe overlapping) mentions\n",
    "                feature_tags = all_nets[\"ner_net\"].crf.spans_to_tags(\n",
    "                    torch.arange(len(observed_mentions), device=observed_mentions.device),\n",
    "                    batch[\"mention\", \"begin\"][observed_mentions], \n",
    "                    batch[\"mention\", \"end\"][observed_mentions], \n",
    "                    batch[\"mention\", \"ner_label\"][observed_mentions], \n",
    "                    n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                    n_samples=len(observed_mentions),\n",
    "                )\n",
    "                tag_mention, tag_positions = feature_tags.nonzero(as_tuple=True)\n",
    "                tag_sentence = batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"]][observed_mentions][tag_mention]\n",
    "                tag_values = feature_tags[tag_mention, tag_positions]\n",
    "                tag_embeds = torch.zeros(*batch[\"sentence\", \"token\"].shape[:2], tag_dim, device=tg.device).view(-1, tag_dim).index_add_(\n",
    "                    dim=0,\n",
    "                    index=tag_sentence * batch[\"sentence\", \"token\"].shape[1] + tag_positions, \n",
    "                    source=all_nets[\"tag_embeddings\"].weight[tag_values-1]).view(*batch[\"sentence\", \"token\"].shape[:2], tag_dim)\n",
    "\n",
    "                ##################################\n",
    "                #       RUN THE NER MODEL        #\n",
    "                ##################################\n",
    "                # Run the model argmax here, we compute tag scores and embeddings\n",
    "                mask = batch[\"token_mask\"]\n",
    "                ner_res = all_nets[\"ner_net\"](\n",
    "                    tokens = batch[\"token\"],\n",
    "                    mask = mask,\n",
    "                    tag_embeds = tag_embeds,\n",
    "                    return_embeddings=True,\n",
    "                )\n",
    "                scores = ner_res[\"scores\"]\n",
    "                embeds = ner_res[\"embeddings\"]\n",
    "\n",
    "                # Run the linear CRF Viterbi algorithm to compute the most likely sequence\n",
    "                spans = all_nets[\"ner_net\"].crf.tags_to_spans(all_nets[\"ner_net\"].crf.decode(scores, mask), mask)\n",
    "\n",
    "                # Save predicted mentions\n",
    "                pred_batch = Batcher({\n",
    "                    \"mention\": {\n",
    "                        \"mention_id\": torch.arange(n_mentions, n_mentions+len(spans[\"span_doc_id\"]), device=device),\n",
    "                        \"begin\": spans[\"span_begin\"],\n",
    "                        \"end\": spans[\"span_end\"],\n",
    "                        \"ner_label\": spans[\"span_label\"],\n",
    "                        \"@sentence_id\": spans[\"span_doc_id\"],\n",
    "                    },\n",
    "                    \"sentence\": dict(batch[\"sentence\", [\"sentence_id\", \"doc_id\"]]),\n",
    "                    \"doc\": dict(batch[\"doc\"])}, \n",
    "                    check=False)\n",
    "                pred_batches.append(pred_batch)\n",
    "                n_mentions += len(spans[\"span_doc_id\"])\n",
    "\n",
    "                ##################################\n",
    "                #      NER LOSS COMPUTATION      #\n",
    "                ##################################\n",
    "                matched_mentions = select_closest_non_overlapping_gold_mentions(\n",
    "                    gold_ids=target_mentions,\n",
    "                    gold_sentence_ids=batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"]][target_mentions],\n",
    "                    gold_begins=batch[\"mention\", \"begin\"][target_mentions],\n",
    "                    gold_ends=batch[\"mention\", \"end\"][target_mentions],\n",
    "\n",
    "                    pred_sentence_ids=spans[\"span_doc_id\"],\n",
    "                    pred_begins=spans[\"span_begin\"],\n",
    "                    pred_ends=spans[\"span_end\"],\n",
    "\n",
    "                    zone_mention_id=batch[\"zone\", \"@mention_id\"],\n",
    "                    zone_mask=batch[\"zone\", \"mention_mask\"],\n",
    "\n",
    "                    gold_conflicts=batch[\"mention\", \"@conflict_mention_id\"],\n",
    "                    gold_conflicts_mask=batch[\"mention\", \"conflict_mask\"],\n",
    "                )\n",
    "                n_matched_mentions += len(matched_mentions)\n",
    "                gold_batches.append(batch[\"mention\", matched_mentions].sparsify())\n",
    "\n",
    "                # Compute the tokens label tag of the selected non-overlapping gold mentions to infer from the model\n",
    "                target_tags = all_nets[\"ner_net\"].crf.spans_to_tags(\n",
    "                    batch[\"zone\", \"@sentence_id\"][batch[\"mention\", \"@zone_id\"][matched_mentions]],\n",
    "                    batch[\"mention\", \"begin\"][matched_mentions], \n",
    "                    batch[\"mention\", \"end\"][matched_mentions], \n",
    "                    batch[\"mention\", \"ner_label\"][matched_mentions], \n",
    "                    n_tokens=batch[\"sentence\", \"token\"].shape[1],\n",
    "                    n_samples=batch[\"sentence\", \"token\"].shape[0],\n",
    "                )\n",
    "                # Run the linear CRF forward algorithm on the tokens to compute the loglikelihood of the targets\n",
    "                ner_loss = -all_nets[\"ner_net\"].crf(scores, mask, target_tags, reduction=\"mean\")\n",
    "                total_train_ner_loss += float(ner_loss) * len(batch[\"sentence\"])\n",
    "                total_train_ner_size += len(batch[\"sentence\"])\n",
    "\n",
    "                loss = ner_loss\n",
    "\n",
    "                # Perform optimization step\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(all_nets.parameters(), max_grad_norm)\n",
    "                optim.step()\n",
    "                for schedule_name, schedule in schedules.items():\n",
    "                    schedule.step()\n",
    "\n",
    "        # Compute precision, recall and f1 on train set\n",
    "        ner_pred = Batcher.concat(pred_batches)\n",
    "        ner_gold = Batcher.concat(gold_batches)\n",
    "\n",
    "        train_metrics    = compute_scores(ner_pred, ner_gold, prefix='train_')\n",
    "        val_metrics     = compute_scores(extract_mentions(val_batcher, all_nets=all_nets), val_batcher, prefix='val_',\n",
    "            queries={\n",
    "                \"3.1\": \"ner_label in ['NEG']\",\n",
    "                #\"3.2\": \"ner_label in ['anatomie', 'dose', 'examen', 'mode', 'moment', 'substance', 'traitement', 'valeur']\",\n",
    "            }\n",
    "                                        )\n",
    "        # final_schedule.step(val_f1, state[\"epoch\"])\n",
    "\n",
    "        return \\\n",
    "        {\n",
    "            \"train_ner_loss\": total_train_ner_loss / max(total_train_ner_size, 1),\n",
    "            **train_metrics,\n",
    "            # **val_metrics,\n",
    "            **val_metrics,\n",
    "            \"val_macro_f1\": val_metrics[\"val_3.1_f1\"], #(val_metrics[\"val_3.1_f1\"] + val_metrics[\"val_3.2_f1\"]) / 2.,\n",
    "            \"n_matched\": n_matched_mentions,\n",
    "            \"lr\": schedules['lr'].get_val()[0],\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        best, history = run_optimization(\n",
    "            main_score = \"val_f1\", # do not earlystop based on validation\n",
    "            metrics_info=metrics_info,\n",
    "            max_epoch=200,\n",
    "            patience=None,\n",
    "            state=state, \n",
    "            cache_policy=\"all\", # only store metrics, not checkpoints\n",
    "            cache=get_cache(\"daloux\", {\"seed\": seed, \"train_batcher\": train_batcher, \"val_batcher\": None, \"random_perm\": random_perm, \"observed_zone_sizes\": observed_zone_sizes, \"batch_size\": batch_size, \"max_grad_norm\": max_grad_norm, **state}, loader=torch.load, dumper=torch.save),  # where to store the model (main name + hashed parameters)\n",
    "            epoch_fn=run_epoch,\n",
    "            n_save_checkpoints=2,\n",
    "#             exit_on_score=0.92,\n",
    "        )\n",
    "        # histories.append({\"layer\": layer, \"hidden_dim\": hidden_dim, \"scheme\": scheme, \"seed\": seed, \"history\": history})\n",
    "    except Exception as e:\n",
    "        \n",
    "        # We catch any exception otherwise some variables (including torch parameters on the gpu) end up being stored globally in sys.last_value, leading to memory errors)\n",
    "        traceback.print_exc()\n",
    "        break.\n",
    "    finally:\n",
    "        pass\n",
    "        #del optim, schedules, final_schedule, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test \n",
    "(to be fair, avoid executing this part of the notebook to often, or use the training set instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d3de49966fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbert_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-large\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;31m#load_genia_ner()#load_from_brat(root.resource(\"deft_2020/t3-test\"), doc_attributes={\"source\": \"real\"})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens, test_deltas, _ = preprocess(\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "bert_name = \"bert-large\"\n",
    "test_dataset=test_dataset#load_genia_ner()#load_from_brat(root.resource(\"deft_2020/t3-test\"), doc_attributes={\"source\": \"real\"})\n",
    "test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens, test_deltas, _ = preprocess(\n",
    "    dataset=test_dataset,\n",
    "    max_sentence_length=120,\n",
    "    ner_labels=list(vocs[\"ner_label\"]),\n",
    "    bert_name=bert_name,\n",
    "    unknown_labels=\"drop\",\n",
    "    vocabularies=vocs,\n",
    ")\n",
    "test_batcher, test_encoded, test_ids = make_batcher(test_docs, test_sentences, test_zones, test_mentions, test_conflicts, test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the test mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_label       f1    prec  rec  \n",
      "---------------------------------\n",
      "pathologie      0.420 0.593 0.325\n",
      "sosy            0.524 0.530 0.518\n",
      "---------------------------------\n",
      "total           0.514 0.534 0.496\n"
     ]
    }
   ],
   "source": [
    "pred_batcher = extract_mentions(test_batcher, all_nets=all_nets)\n",
    "gold_batcher = test_batcher\n",
    "\n",
    "pred=pd.DataFrame(dict(pred_batcher[\"mention\", [\"sentence_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "gold=pd.DataFrame(dict(gold_batcher[\"mention\", [\"@zone_id\", \"begin\", \"end\", \"ner_label\", \"mention_id\"]]))\n",
    "gold[\"sentence_id\"] = gold_batcher[\"zone\", \"sentence_id\"][gold[\"@zone_id\"]]\n",
    "all_preds.append(pred)\n",
    "\n",
    "print(\"{: <15} {: <5} {: <5} {: <5}\".format(\"ner_label\", \"f1\", \"prec\", \"rec\"))\n",
    "print(\"---------------------------------\")\n",
    "for ner_label_idx, ner_label in enumerate(vocs['ner_label']):\n",
    "    merged = merge_pred_and_gold(\n",
    "        pred.query(f'ner_label == {ner_label_idx}'), \n",
    "        gold.query(f'ner_label == {ner_label_idx}'), \n",
    "        span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "        on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"])\n",
    "    precision = merged['tp'].sum() / merged['pred_count'].sum()\n",
    "    recall = merged['tp'].sum() / merged['gold_count'].sum()\n",
    "    f1 = 2/(1/precision + 1/recall)\n",
    "    f1, precision, recall\n",
    "    print(\"{: <15} {:.3f} {:.3f} {:.3f}\".format(str(ner_label), f1, precision, recall))\n",
    "agg = compute_metrics(merge_pred_and_gold(\n",
    "    pred,\n",
    "    gold,\n",
    "    span_policy='exact',  # only partially match spans with strict bounds, we could also eval with 'exact' or 'partial'\n",
    "    on=[\"sentence_id\", (\"begin\", \"end\"), \"ner_label\"], atom_gold_level=[\"mention_id\"], atom_pred_level=[\"mention_id\"]))\n",
    "print(\"---------------------------------\")\n",
    "print(\"{: <15} {:.3f} {:.3f} {:.3f}\".format(\"total\", agg[\"f1\"], agg[\"precision\"], agg[\"recall\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_nlp",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
