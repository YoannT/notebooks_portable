{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "# to remove limits on display\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(path='corpus_xavier/*.txt'):\n",
    "    all_files = glob(path)\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    for file in all_files:\n",
    "        with open(file, 'r', encoding='utf8') as f:\n",
    "            lines.extend(f.readlines())\n",
    "\n",
    "    lines = np.array(lines)\n",
    "    \n",
    "    lower_ids = [i for i,l in enumerate(lines) if l[0].islower()]\n",
    "\n",
    "    def consecutive(data, stepsize=1):\n",
    "        return np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "\n",
    "    lower_groups = consecutive(lower_ids)\n",
    "    \n",
    "    processed = []\n",
    "\n",
    "    l_groups = [[g[0]-1, *g] for g in lower_groups]\n",
    "\n",
    "    flattened_groups = [gg for g in l_groups for gg in g]\n",
    "\n",
    "    cpt_grp = 0\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    pbar = tqdm(total=len(lines))\n",
    "    while i < len(lines):\n",
    "\n",
    "        if i not in flattened_groups:\n",
    "            processed.append(lines[i].strip('\\n'))\n",
    "            pbar.update()\n",
    "        else:\n",
    "            group = lower_groups[cpt_grp]\n",
    "            processed.append(' '.join(list(map(lambda x: x.strip('\\n'), [lines[group[0]-1], *lines[group]]))))\n",
    "            cpt_grp += 1\n",
    "            pbar.update(group[-1] - i + 1)\n",
    "            i = group[-1]\n",
    "\n",
    "        i += 1\n",
    "    pbar.close()\n",
    "    print(\"Preprocessing over\")\n",
    "    \n",
    "    processed_df = pd.DataFrame(processed, columns=['sentences'])\n",
    "#     processed_df['sentences'] = processed_df['sentences'].str.replace('\\d+', '')\n",
    "    processed_df = processed_df.replace('', np.nan).dropna()\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# processed_df = get_corpus()\n",
    "# processed_df.to_csv('corpus_xavier/annot_test.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filters(\n",
    "    folder='context_java_abdaoui',\n",
    "    neg_only=True,\n",
    "    ):\n",
    "    all_regex = []\n",
    "    \n",
    "    regex_files = glob(folder + '/regex*.txt')\n",
    "    \n",
    "    for file in regex_files:\n",
    "        with open(file, 'r', encoding=\"utf8\") as f:\n",
    "            regex = f.readlines()[0]\n",
    "            try:\n",
    "                all_regex.extend(literal_eval(regex))\n",
    "            except:\n",
    "                all_regex.extend(regex.strip(\"\\\"\").split('\", \"'))\n",
    "                \n",
    "    formatted_regex = [regex.replace('\"', '').replace(\"'\", '').replace(\" ,\", ',').rsplit(',',2) for regex in all_regex]\n",
    "\n",
    "    regex_df = pd.DataFrame(formatted_regex, columns=[\"regex\", \"scope\", \"type\"])\n",
    "    \n",
    "    regex_df.drop_duplicates('regex', inplace=True)\n",
    "    \n",
    "    if neg_only:\n",
    "        regex_df = regex_df[regex_df['type'].isin(['neg'])]\n",
    "    \n",
    "    return regex_df['regex']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negation regex from preprocessed df\n",
    "def keep_neg_only(df):\n",
    "    # safe regexs from filters\n",
    "    # remove 'de' to not keep too much\n",
    "    filters = get_filters()\n",
    "    regex_filters = [re.escape(' %s '%(f)) for f in filters.values if f not in ['de', '(de']]\n",
    "\n",
    "    all_filters_str = '|'.join(regex_filters)\n",
    "\n",
    "    filtered_df = df[df['sentences'].str.contains(all_filters_str)]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# pp_df = pd.read_csv('corpus_xavier/annot_test.csv')\n",
    "# filtered_pp_df = keep_neg_only(pp_df)\n",
    "# filtered_pp_df.to_csv('corpus_xavier/annot_test_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pp_df = pd.read_csv('corpus_xavier/annot_test_filtered.csv').rename(columns={'sentences': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_pp_df.head(100).to_csv('corpus_xavier/annot_test_filtered100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters, accents and unnecessary spaces\n",
    "# remove numbers\n",
    "#filtered_pp_df['text'] = filtered_pp_df['text'].str.replace('\\W', ' ')\n",
    "# remove accents\n",
    "filtered_pp_df = filtered_pp_df.apply(lambda x: x.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))\n",
    "# remove double spaces\n",
    "filtered_pp_df['text'] = filtered_pp_df['text'].apply(lambda x: ' '.join(x.strip(' ').split()))\n",
    "\n",
    "filtered_pp_df.to_csv('corpus_xavier/annot_test_filtered_noaccent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
